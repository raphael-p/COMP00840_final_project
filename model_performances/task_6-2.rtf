{\rtf1\ansi\ansicpg1252\cocoartf1671\cocoasubrtf400
{\fonttbl\f0\fswiss\fcharset0 Helvetica-Bold;\f1\fswiss\fcharset0 Helvetica;}
{\colortbl;\red255\green255\blue255;}
{\*\expandedcolortbl;;}
\paperw11900\paperh16840\margl1440\margr1440\vieww27520\viewh16580\viewkind0
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardirnatural\partightenfactor0

\f0\b\fs24 \cf0 \ul \ulc0 NETWORK 1
\fs20 \ulnone \
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardirnatural\partightenfactor0

\f1\b0 \cf0 _________________________________________________________________\
Layer (type)                 Output Shape              Param #   \
=================================================================\
lstm_1 (LSTM)                (None, 128)               219648    \
_________________________________________________________________\
dense_1 (Dense)              (None, 1)                 129       \
=================================================================\
Total params: 219,777\
Trainable params: 219,777\
Non-trainable params: 0\
_________________________________________________________________\
None\
Minibatch size: 40\
Timesteps: 6\
Train on 109810 samples, validate on 13332 samples\
Epoch 1/10\
 - 85s - loss: 0.5078 - acc: 0.7697 - f1: 0.8567 - precision: 0.7775 - recall: 0.9605 - val_loss: 0.6732 - val_acc: 0.6277 - val_f1: 0.7086 - val_precision: 0.5795 - val_recall: 0.9257\
Epoch 2/10\
 - 86s - loss: 0.4714 - acc: 0.7907 - f1: 0.8682 - precision: 0.7950 - recall: 0.9611 - val_loss: 0.6049 - val_acc: 0.6514 - val_f1: 0.7082 - val_precision: 0.6058 - val_recall: 0.8662\
Epoch 3/10\
 - 77s - loss: 0.4589 - acc: 0.7985 - f1: 0.8727 - precision: 0.8011 - recall: 0.9626 - val_loss: 0.6570 - val_acc: 0.6433 - val_f1: 0.7198 - val_precision: 0.5897 - val_recall: 0.9371\
Epoch 4/10\
 - 83s - loss: 0.4479 - acc: 0.8046 - f1: 0.8759 - precision: 0.8077 - recall: 0.9613 - val_loss: 0.7006 - val_acc: 0.6333 - val_f1: 0.7207 - val_precision: 0.5797 - val_recall: 0.9667\
Epoch 5/10\
 - 77s - loss: 0.4354 - acc: 0.8116 - f1: 0.8799 - precision: 0.8133 - recall: 0.9626 - val_loss: 0.6295 - val_acc: 0.6595 - val_f1: 0.7280 - val_precision: 0.6030 - val_recall: 0.9322\
Epoch 6/10\
 - 76s - loss: 0.4255 - acc: 0.8169 - f1: 0.8830 - precision: 0.8178 - recall: 0.9635 - val_loss: 0.6352 - val_acc: 0.6514 - val_f1: 0.7280 - val_precision: 0.5942 - val_recall: 0.9536\
Epoch 7/10\
 - 77s - loss: 0.4169 - acc: 0.8210 - f1: 0.8853 - precision: 0.8220 - recall: 0.9631 - val_loss: 0.6762 - val_acc: 0.6604 - val_f1: 0.7326 - val_precision: 0.6014 - val_recall: 0.9509\
Epoch 8/10\
 - 82s - loss: 0.4084 - acc: 0.8256 - f1: 0.8880 - precision: 0.8260 - recall: 0.9641 - val_loss: 0.6660 - val_acc: 0.6571 - val_f1: 0.7322 - val_precision: 0.5979 - val_recall: 0.9584\
Epoch 9/10\
 - 76s - loss: 0.4003 - acc: 0.8298 - f1: 0.8903 - precision: 0.8302 - recall: 0.9637 - val_loss: 0.6219 - val_acc: 0.6703 - val_f1: 0.7372 - val_precision: 0.6102 - val_recall: 0.9449\
Epoch 10/10\
 - 83s - loss: 0.3920 - acc: 0.8339 - f1: 0.8929 - precision: 0.8337 - recall: 0.9648 - val_loss: 0.6467 - val_acc: 0.6793 - val_f1: 0.7393 - val_precision: 0.6189 - val_recall: 0.9310
\f0\b \
Loss: 64.67%\
Accuracy: 67.93%\
F1 score: 73.80%\
Precision: 61.86%\
Recall: 93.13%\
\
\
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardirnatural\partightenfactor0

\fs24 \cf0 \ul NETWORK 2\
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardirnatural\partightenfactor0

\f1\b0\fs20 \cf0 \ulnone _________________________________________________________________\
Layer (type)                 Output Shape              Param #   \
=================================================================\
lstm_1 (LSTM)                (None, 6, 300)            721200    \
_________________________________________________________________\
lstm_2 (LSTM)                (None, 300)               721200    \
_________________________________________________________________\
dense_1 (Dense)              (None, 1)                 301       \
=================================================================\
Total params: 1,442,701\
Trainable params: 1,442,701\
Non-trainable params: 0\
_________________________________________________________________\
None\
Minibatch size: 30\
Timesteps: 6\
Train on 109810 samples, validate on 1000 samples\
Epoch 1/20\
 - 456s - loss: 0.5061 - acc: 0.7718 - f1: 0.8576 - precision: 0.7783 - recall: 0.9626 - val_loss: 0.7640 - val_acc: 0.5980 - val_f1: 0.7066 - val_precision: 0.5603 - val_recall: 0.9743\
Epoch 2/20\
 - 415s - loss: 0.4651 - acc: 0.7958 - f1: 0.8707 - precision: 0.7997 - recall: 0.9618 - val_loss: 0.6704 - val_acc: 0.6490 - val_f1: 0.7285 - val_precision: 0.5958 - val_recall: 0.9530\
Epoch 3/20\
 - 407s - loss: 0.4449 - acc: 0.8067 - f1: 0.8766 - precision: 0.8093 - recall: 0.9618 - val_loss: 0.6321 - val_acc: 0.6540 - val_f1: 0.7306 - val_precision: 0.6017 - val_recall: 0.9472\
Epoch 4/20\
 - 405s - loss: 0.4283 - acc: 0.8160 - f1: 0.8820 - precision: 0.8171 - recall: 0.9638 - val_loss: 0.6193 - val_acc: 0.6700 - val_f1: 0.7412 - val_precision: 0.6127 - val_recall: 0.9549\
Epoch 5/20\
 - 405s - loss: 0.4153 - acc: 0.8224 - f1: 0.8856 - precision: 0.8224 - recall: 0.9643 - val_loss: 0.6128 - val_acc: 0.6740 - val_f1: 0.7420 - val_precision: 0.6174 - val_recall: 0.9474\
Epoch 6/20\
 - 411s - loss: 0.4027 - acc: 0.8287 - f1: 0.8894 - precision: 0.8289 - recall: 0.9646 - val_loss: 0.6463 - val_acc: 0.6680 - val_f1: 0.7403 - val_precision: 0.6110 - val_recall: 0.9564\
Epoch 7/20\
 - 407s - loss: 0.3909 - acc: 0.8339 - f1: 0.8922 - precision: 0.8345 - recall: 0.9637 - val_loss: 0.6205 - val_acc: 0.6730 - val_f1: 0.7306 - val_precision: 0.6246 - val_recall: 0.8988\
Epoch 8/20\
 - 407s - loss: 0.3784 - acc: 0.8397 - f1: 0.8956 - precision: 0.8395 - recall: 0.9645 - val_loss: 0.6397 - val_acc: 0.6790 - val_f1: 0.7423 - val_precision: 0.6250 - val_recall: 0.9326\
Epoch 9/20\
 - 407s - loss: 0.3657 - acc: 0.8446 - f1: 0.8984 - precision: 0.8450 - recall: 0.9638 - val_loss: 0.6324 - val_acc: 0.6770 - val_f1: 0.7364 - val_precision: 0.6212 - val_recall: 0.9169\
Epoch 10/20\
 - 413s - loss: 0.3529 - acc: 0.8512 - f1: 0.9023 - precision: 0.8510 - recall: 0.9647 - val_loss: 0.6197 - val_acc: 0.6790 - val_f1: 0.7431 - val_precision: 0.6225 - val_recall: 0.9375\
Epoch 11/20\
 - 408s - loss: 0.3398 - acc: 0.8570 - f1: 0.9059 - precision: 0.8578 - recall: 0.9641 - val_loss: 0.6205 - val_acc: 0.7010 - val_f1: 0.7446 - val_precision: 0.6538 - val_recall: 0.8806\
Epoch 12/20\
 - 406s - loss: 0.3250 - acc: 0.8626 - f1: 0.9093 - precision: 0.8630 - recall: 0.9650 - val_loss: 0.6908 - val_acc: 0.6960 - val_f1: 0.7483 - val_precision: 0.6404 - val_recall: 0.9142\
Epoch 13/20\
 - 406s - loss: 0.3125 - acc: 0.8682 - f1: 0.9124 - precision: 0.8693 - recall: 0.9641 - val_loss: 0.7178 - val_acc: 0.6890 - val_f1: 0.7395 - val_precision: 0.6390 - val_recall: 0.8949\
Epoch 14/20\
 - 409s - loss: 0.2985 - acc: 0.8735 - f1: 0.9158 - precision: 0.8752 - recall: 0.9642 - val_loss: 0.7431 - val_acc: 0.7000 - val_f1: 0.7365 - val_precision: 0.6573 - val_recall: 0.8507\
Epoch 15/20\
 - 409s - loss: 0.2838 - acc: 0.8797 - f1: 0.9195 - precision: 0.8811 - recall: 0.9653 - val_loss: 0.7338 - val_acc: 0.6860 - val_f1: 0.7390 - val_precision: 0.6348 - val_recall: 0.9005\
Epoch 16/20\
 - 407s - loss: 0.2693 - acc: 0.8856 - f1: 0.9234 - precision: 0.8873 - recall: 0.9661 - val_loss: 0.7962 - val_acc: 0.6850 - val_f1: 0.7250 - val_precision: 0.6498 - val_recall: 0.8373\
Epoch 17/20\
 - 407s - loss: 0.2554 - acc: 0.8906 - f1: 0.9263 - precision: 0.8927 - recall: 0.9660 - val_loss: 0.8569 - val_acc: 0.6950 - val_f1: 0.7299 - val_precision: 0.6605 - val_recall: 0.8309\
Epoch 18/20\
 - 418s - loss: 0.2413 - acc: 0.8959 - f1: 0.9297 - precision: 0.8993 - recall: 0.9656 - val_loss: 0.9178 - val_acc: 0.6890 - val_f1: 0.7288 - val_precision: 0.6524 - val_recall: 0.8423\
Epoch 19/20\
 - 406s - loss: 0.2265 - acc: 0.9023 - f1: 0.9337 - precision: 0.9066 - recall: 0.9656 - val_loss: 0.9251 - val_acc: 0.6920 - val_f1: 0.7319 - val_precision: 0.6523 - val_recall: 0.8490\
Epoch 20/20\
 - 407s - loss: 0.2138 - acc: 0.9071 - f1: 0.9368 - precision: 0.9120 - recall: 0.9658 - val_loss: 1.0356 - val_acc: 0.6950 - val_f1: 0.7333 - val_precision: 0.6579 - val_recall: 0.8488
\f0\b \
Loss: 99.12%\
Accuracy: 70.06%\
F1 score: 73.88%\
Precision: 64.83%\
Recall: 87.45%\
\
\
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardirnatural\partightenfactor0

\fs24 \cf0 \ul NETWORK 3
\fs20 \ulnone \
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardirnatural\partightenfactor0

\f1\b0 \cf0 _________________________________________________________________\
Layer (type)                 Output Shape              Param #   \
=================================================================\
lstm_1 (LSTM)                (None, 6, 500)            1602000   \
_________________________________________________________________\
lstm_2 (LSTM)                (None, 500)               2002000   \
_________________________________________________________________\
dense_1 (Dense)              (None, 1)                 501       \
=================================================================\
Total params: 3,604,501\
Trainable params: 3,604,501\
Non-trainable params: 0\
_________________________________________________________________\
None\
Minibatch size: 30\
Timesteps: 6\
Train on 109810 samples, validate on 1000 samples\
Epoch 1/20\
 - 998s - loss: 0.5060 - acc: 0.7735 - f1: 0.8587 - precision: 0.7794 - recall: 0.9639 - val_loss: 0.7236 - val_acc: 0.6020 - val_f1: 0.7089 - val_precision: 0.5623 - val_recall: 0.9766\
Epoch 2/20\
 - 877s - loss: 0.4648 - acc: 0.7960 - f1: 0.8709 - precision: 0.7980 - recall: 0.9646 - val_loss: 0.6138 - val_acc: 0.6630 - val_f1: 0.7296 - val_precision: 0.6133 - val_recall: 0.9184\
Epoch 3/20\
 - 1002s - loss: 0.4448 - acc: 0.8066 - f1: 0.8765 - precision: 0.8088 - recall: 0.9623 - val_loss: 0.6029 - val_acc: 0.6640 - val_f1: 0.7331 - val_precision: 0.6114 - val_recall: 0.9335\
Epoch 4/20\
 - 1042s - loss: 0.4260 - acc: 0.8170 - f1: 0.8825 - precision: 0.8186 - recall: 0.9628 - val_loss: 0.6065 - val_acc: 0.6680 - val_f1: 0.7351 - val_precision: 0.6139 - val_recall: 0.9327\
Epoch 5/20\
 - 968s - loss: 0.4110 - acc: 0.8250 - f1: 0.8872 - precision: 0.8245 - recall: 0.9656 - val_loss: 0.6616 - val_acc: 0.6630 - val_f1: 0.7341 - val_precision: 0.6084 - val_recall: 0.9422\
Epoch 6/20\
 - 895s - loss: 0.3969 - acc: 0.8311 - f1: 0.8905 - precision: 0.8313 - recall: 0.9639 - val_loss: 0.6519 - val_acc: 0.6720 - val_f1: 0.7401 - val_precision: 0.6162 - val_recall: 0.9430\
Epoch 7/20\
 - 928s - loss: 0.3823 - acc: 0.8378 - f1: 0.8945 - precision: 0.8377 - recall: 0.9645 - val_loss: 0.6065 - val_acc: 0.6810 - val_f1: 0.7360 - val_precision: 0.6323 - val_recall: 0.8957\
Epoch 8/20\
 - 992s - loss: 0.3680 - acc: 0.8439 - f1: 0.8980 - precision: 0.8438 - recall: 0.9644 - val_loss: 0.6547 - val_acc: 0.6690 - val_f1: 0.7366 - val_precision: 0.6139 - val_recall: 0.9369\
Epoch 9/20\
 - 948s - loss: 0.3518 - acc: 0.8511 - f1: 0.9023 - precision: 0.8508 - recall: 0.9650 - val_loss: 0.6026 - val_acc: 0.6910 - val_f1: 0.7396 - val_precision: 0.6400 - val_recall: 0.8896\
Epoch 10/20\
 - 912s - loss: 0.3353 - acc: 0.8577 - f1: 0.9062 - precision: 0.8579 - recall: 0.9647 - val_loss: 0.6474 - val_acc: 0.6920 - val_f1: 0.7462 - val_precision: 0.6372 - val_recall: 0.9135\
Epoch 11/20\
 - 912s - loss: 0.3200 - acc: 0.8634 - f1: 0.9097 - precision: 0.8638 - recall: 0.9649 - val_loss: 0.6832 - val_acc: 0.6980 - val_f1: 0.7502 - val_precision: 0.6396 - val_recall: 0.9198\
Epoch 12/20\
 - 884s - loss: 0.3028 - acc: 0.8717 - f1: 0.9148 - precision: 0.8726 - recall: 0.9652 - val_loss: 0.6388 - val_acc: 0.6910 - val_f1: 0.7381 - val_precision: 0.6432 - val_recall: 0.8807\
Epoch 13/20\
 - 867s - loss: 0.2861 - acc: 0.8777 - f1: 0.9183 - precision: 0.8795 - recall: 0.9646 - val_loss: 0.7113 - val_acc: 0.7070 - val_f1: 0.7481 - val_precision: 0.6598 - val_recall: 0.8786\
Epoch 14/20\
 - 864s - loss: 0.2672 - acc: 0.8847 - f1: 0.9227 - precision: 0.8866 - recall: 0.9654 - val_loss: 0.7438 - val_acc: 0.7040 - val_f1: 0.7456 - val_precision: 0.6598 - val_recall: 0.8721\
Epoch 15/20\
 - 869s - loss: 0.2494 - acc: 0.8919 - f1: 0.9271 - precision: 0.8950 - recall: 0.9650 - val_loss: 0.7400 - val_acc: 0.6950 - val_f1: 0.7368 - val_precision: 0.6518 - val_recall: 0.8632\
Epoch 16/20\
 - 864s - loss: 0.2315 - acc: 0.8994 - f1: 0.9319 - precision: 0.9027 - recall: 0.9661 - val_loss: 0.8800 - val_acc: 0.6980 - val_f1: 0.7400 - val_precision: 0.6513 - val_recall: 0.8696\
Epoch 17/20\
 - 866s - loss: 0.2158 - acc: 0.9058 - f1: 0.9360 - precision: 0.9097 - recall: 0.9669 - val_loss: 0.9932 - val_acc: 0.7000 - val_f1: 0.7388 - val_precision: 0.6577 - val_recall: 0.8565\
Epoch 18/20\
 - 864s - loss: 0.2013 - acc: 0.9124 - f1: 0.9402 - precision: 0.9173 - recall: 0.9670 - val_loss: 0.9658 - val_acc: 0.6980 - val_f1: 0.7289 - val_precision: 0.6619 - val_recall: 0.8210\
Epoch 19/20\
 - 938s - loss: 0.1859 - acc: 0.9191 - f1: 0.9446 - precision: 0.9245 - recall: 0.9681 - val_loss: 0.9870 - val_acc: 0.7000 - val_f1: 0.7338 - val_precision: 0.6624 - val_recall: 0.8370\
Epoch 20/20\
 - 3690s - loss: 0.1746 - acc: 0.9238 - f1: 0.9477 - precision: 0.9294 - recall: 0.9692 - val_loss: 1.0872 - val_acc: 0.7000 - val_f1: 0.7358 - val_precision: 0.6623 - val_recall: 0.8414
\f0\b \
Loss: 108.09%\
Accuracy: 69.60%\
F1 score: 73.18%\
Precision: 64.77%\
Recall: 85.74%
\f1\b0 \
\
\
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardirnatural\partightenfactor0

\f0\b\fs24 \cf0 \ul NETWORK 4
\f1\b0\fs20 \ulnone \
_________________________________________________________________\
Layer (type)                 Output Shape              Param #   \
=================================================================\
lstm_1 (LSTM)                (None, 200)               400800    \
_________________________________________________________________\
dense_1 (Dense)              (None, 1)                 201       \
=================================================================\
Total params: 401,001\
Trainable params: 401,001\
Non-trainable params: 0\
_________________________________________________________________\
None\
Minibatch size: 50\
Timesteps: 6\
Train on 109810 samples, validate on 1000 samples\
Epoch 1/10\
 - 106s - loss: 0.5071 - acc: 0.7706 - f1: 0.8578 - precision: 0.7781 - recall: 0.9606 - val_loss: 0.6789 - val_acc: 0.6060 - val_f1: 0.7109 - val_precision: 0.5659 - val_recall: 0.9654\
Epoch 2/10\
 - 904s - loss: 0.4702 - acc: 0.7919 - f1: 0.8693 - precision: 0.7960 - recall: 0.9614 - val_loss: 0.6932 - val_acc: 0.6130 - val_f1: 0.7153 - val_precision: 0.5712 - val_recall: 0.9680\
Epoch 3/10\
 - 110s - loss: 0.4573 - acc: 0.7992 - f1: 0.8732 - precision: 0.8022 - recall: 0.9618 - val_loss: 0.6728 - val_acc: 0.6200 - val_f1: 0.7203 - val_precision: 0.5745 - val_recall: 0.9752\
Epoch 4/10\
 - 132s - loss: 0.4456 - acc: 0.8054 - f1: 0.8766 - precision: 0.8088 - recall: 0.9603 - val_loss: 0.6372 - val_acc: 0.6600 - val_f1: 0.7373 - val_precision: 0.6058 - val_recall: 0.9522\
Epoch 5/10\
 - 109s - loss: 0.4342 - acc: 0.8129 - f1: 0.8809 - precision: 0.8149 - recall: 0.9618 - val_loss: 0.6189 - val_acc: 0.6660 - val_f1: 0.7303 - val_precision: 0.6176 - val_recall: 0.9039\
Epoch 6/10\
 - 117s - loss: 0.4245 - acc: 0.8172 - f1: 0.8835 - precision: 0.8186 - recall: 0.9629 - val_loss: 0.6761 - val_acc: 0.6610 - val_f1: 0.7371 - val_precision: 0.6084 - val_recall: 0.9476\
Epoch 7/10\
 - 119s - loss: 0.4167 - acc: 0.8219 - f1: 0.8863 - precision: 0.8223 - recall: 0.9644 - val_loss: 0.6568 - val_acc: 0.6540 - val_f1: 0.7356 - val_precision: 0.6018 - val_recall: 0.9584\
Epoch 8/10\
 - 107s - loss: 0.4077 - acc: 0.8254 - f1: 0.8882 - precision: 0.8257 - recall: 0.9643 - val_loss: 0.6050 - val_acc: 0.6680 - val_f1: 0.7344 - val_precision: 0.6176 - val_recall: 0.9171\
Epoch 9/10\
 - 95s - loss: 0.3994 - acc: 0.8299 - f1: 0.8910 - precision: 0.8299 - recall: 0.9648 - val_loss: 0.6474 - val_acc: 0.6710 - val_f1: 0.7367 - val_precision: 0.6191 - val_recall: 0.9201\
Epoch 10/10\
 - 106s - loss: 0.3907 - acc: 0.8334 - f1: 0.8930 - precision: 0.8334 - recall: 0.9648 - val_loss: 0.6428 - val_acc: 0.6730 - val_f1: 0.7327 - val_precision: 0.6260 - val_recall: 0.8958\
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardirnatural\partightenfactor0

\f0\b \cf0 Loss: 64.02%\
Accuracy: 68.30%\
F1 score: 73.76%\
Precision: 62.43%\
Recall: 91.82%\
\
\
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardirnatural\partightenfactor0

\fs24 \cf0 \ul NETWORK 5
\fs20 \ulnone \
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardirnatural\partightenfactor0

\f1\b0 \cf0 _________________________________________________________________\
Layer (type)                 Output Shape              Param #   \
=================================================================\
lstm_1 (LSTM)                (None, 128)               219648    \
_________________________________________________________________\
dense_1 (Dense)              (None, 1)                 129       \
=================================================================\
Total params: 219,777\
Trainable params: 219,777\
Non-trainable params: 0\
_________________________________________________________________\
None\
Minibatch size: 100\
Timesteps: 6\
Train on 109810 samples, validate on 1000 samples\
Epoch 1/5\
 - 48s - loss: 0.5206 - acc: 0.7615 - f1: 0.8538 - precision: 0.7707 - recall: 0.9604 - val_loss: 0.7667 - val_acc: 0.5900 - val_f1: 0.7069 - val_precision: 0.5546 - val_recall: 0.9825\
Epoch 2/5\
 - 42s - loss: 0.4794 - acc: 0.7859 - f1: 0.8663 - precision: 0.7917 - recall: 0.9586 - val_loss: 0.6883 - val_acc: 0.6200 - val_f1: 0.7196 - val_precision: 0.5754 - val_recall: 0.9688\
Epoch 3/5\
 - 43s - loss: 0.4679 - acc: 0.7921 - f1: 0.8701 - precision: 0.7959 - recall: 0.9619 - val_loss: 0.6333 - val_acc: 0.6330 - val_f1: 0.7239 - val_precision: 0.5860 - val_recall: 0.9561\
Epoch 4/5\
 - 41s - loss: 0.4588 - acc: 0.7976 - f1: 0.8735 - precision: 0.7994 - recall: 0.9645 - val_loss: 0.6512 - val_acc: 0.6370 - val_f1: 0.7230 - val_precision: 0.5897 - val_recall: 0.9422\
Epoch 5/5\
 - 47s - loss: 0.4521 - acc: 0.8016 - f1: 0.8757 - precision: 0.8030 - recall: 0.9648 - val_loss: 0.6736 - val_acc: 0.6520 - val_f1: 0.7318 - val_precision: 0.6010 - val_recall: 0.9440
\f0\b \
Loss: 68.08%\
Accuracy: 64.34%\
F1 score: 71.92%\
Precision: 58.93%\
Recall: 94.02%
\f1\b0 \
\
\
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardirnatural\partightenfactor0

\f0\b\fs24 \cf0 \ul NETWORK 6
\f1\b0\fs20 \ulnone \
_________________________________________________________________\
Layer (type)                 Output Shape              Param #   \
=================================================================\
lstm_1 (LSTM)                (None, 6, 300)            721200    \
_________________________________________________________________\
lstm_2 (LSTM)                (None, 6, 300)            721200    \
_________________________________________________________________\
lstm_3 (LSTM)                (None, 6, 300)            721200    \
_________________________________________________________________\
lstm_4 (LSTM)                (None, 300)               721200    \
_________________________________________________________________\
dense_1 (Dense)              (None, 1)                 301       \
=================================================================\
Total params: 2,885,101\
Trainable params: 2,885,101\
Non-trainable params: 0\
_________________________________________________________________\
None\
Minibatch size: 50\
Timesteps: 6\
Train on 109810 samples, validate on 1000 samples\
Epoch 1/40\
 - 639s - loss: 0.5096 - acc: 0.7702 - f1: 0.8575 - precision: 0.7784 - recall: 0.9597 - val_loss: 0.6228 - val_acc: 0.6340 - val_f1: 0.7149 - val_precision: 0.5907 - val_recall: 0.9154\
Epoch 2/40\
 - 582s - loss: 0.4753 - acc: 0.7897 - f1: 0.8680 - precision: 0.7936 - recall: 0.9620 - val_loss: 0.6385 - val_acc: 0.6350 - val_f1: 0.7221 - val_precision: 0.5883 - val_recall: 0.9453\
Epoch 3/40\
 - 633s - loss: 0.4599 - acc: 0.7980 - f1: 0.8729 - precision: 0.8002 - recall: 0.9638 - val_loss: 0.6671 - val_acc: 0.6350 - val_f1: 0.7253 - val_precision: 0.5863 - val_recall: 0.9608\
Epoch 4/40\
 - 1354s - loss: 0.4477 - acc: 0.8042 - f1: 0.8763 - precision: 0.8061 - recall: 0.9635 - val_loss: 0.6378 - val_acc: 0.6680 - val_f1: 0.7423 - val_precision: 0.6110 - val_recall: 0.9548\
Epoch 5/40\
 - 634s - loss: 0.4351 - acc: 0.8124 - f1: 0.8808 - precision: 0.8131 - recall: 0.9643 - val_loss: 0.6405 - val_acc: 0.6490 - val_f1: 0.7333 - val_precision: 0.5972 - val_recall: 0.9617\
Epoch 6/40\
 - 586s - loss: 0.4232 - acc: 0.8189 - f1: 0.8845 - precision: 0.8201 - recall: 0.9630 - val_loss: 0.6193 - val_acc: 0.6750 - val_f1: 0.7436 - val_precision: 0.6195 - val_recall: 0.9411\
Epoch 7/40\
 - 565s - loss: 0.4126 - acc: 0.8235 - f1: 0.8870 - precision: 0.8247 - recall: 0.9627 - val_loss: 0.6273 - val_acc: 0.6770 - val_f1: 0.7436 - val_precision: 0.6216 - val_recall: 0.9359\
Epoch 8/40\
 - 565s - loss: 0.4019 - acc: 0.8284 - f1: 0.8898 - precision: 0.8291 - recall: 0.9631 - val_loss: 0.6031 - val_acc: 0.6700 - val_f1: 0.7377 - val_precision: 0.6183 - val_recall: 0.9257\
Epoch 9/40\
 - 565s - loss: 0.3923 - acc: 0.8335 - f1: 0.8928 - precision: 0.8337 - recall: 0.9641 - val_loss: 0.6325 - val_acc: 0.6730 - val_f1: 0.7367 - val_precision: 0.6237 - val_recall: 0.9129\
Epoch 10/40\
 - 572s - loss: 0.3824 - acc: 0.8386 - f1: 0.8958 - precision: 0.8381 - recall: 0.9650 - val_loss: 0.6565 - val_acc: 0.6670 - val_f1: 0.7362 - val_precision: 0.6154 - val_recall: 0.9279\
Epoch 11/40\
 - 570s - loss: 0.3722 - acc: 0.8429 - f1: 0.8983 - precision: 0.8423 - recall: 0.9651 - val_loss: 0.6052 - val_acc: 0.7000 - val_f1: 0.7495 - val_precision: 0.6470 - val_recall: 0.8993\
Epoch 12/40\
 - 555s - loss: 0.3621 - acc: 0.8475 - f1: 0.9011 - precision: 0.8473 - recall: 0.9650 - val_loss: 0.6168 - val_acc: 0.6880 - val_f1: 0.7511 - val_precision: 0.6293 - val_recall: 0.9410\
Epoch 13/40\
 - 554s - loss: 0.3526 - acc: 0.8511 - f1: 0.9031 - precision: 0.8504 - recall: 0.9655 - val_loss: 0.6251 - val_acc: 0.6880 - val_f1: 0.7453 - val_precision: 0.6342 - val_recall: 0.9116\
Epoch 14/40\
 - 555s - loss: 0.3415 - acc: 0.8558 - f1: 0.9059 - precision: 0.8559 - recall: 0.9648 - val_loss: 0.6719 - val_acc: 0.6880 - val_f1: 0.7446 - val_precision: 0.6344 - val_recall: 0.9103\
Epoch 15/40\
 - 560s - loss: 0.3303 - acc: 0.8603 - f1: 0.9086 - precision: 0.8598 - recall: 0.9659 - val_loss: 0.6566 - val_acc: 0.6980 - val_f1: 0.7505 - val_precision: 0.6432 - val_recall: 0.9103\
Epoch 16/40\
 - 562s - loss: 0.3183 - acc: 0.8659 - f1: 0.9120 - precision: 0.8655 - recall: 0.9664 - val_loss: 0.6515 - val_acc: 0.6870 - val_f1: 0.7419 - val_precision: 0.6354 - val_recall: 0.9021\
Epoch 17/40\
 - 554s - loss: 0.3071 - acc: 0.8696 - f1: 0.9142 - precision: 0.8691 - recall: 0.9667 - val_loss: 0.6976 - val_acc: 0.6860 - val_f1: 0.7385 - val_precision: 0.6385 - val_recall: 0.8868\
Epoch 18/40\
 - 557s - loss: 0.2952 - acc: 0.8749 - f1: 0.9174 - precision: 0.8755 - recall: 0.9659 - val_loss: 0.7203 - val_acc: 0.6970 - val_f1: 0.7517 - val_precision: 0.6410 - val_recall: 0.9187\
Epoch 19/40\
 - 554s - loss: 0.2826 - acc: 0.8791 - f1: 0.9201 - precision: 0.8789 - recall: 0.9676 - val_loss: 0.7225 - val_acc: 0.6950 - val_f1: 0.7324 - val_precision: 0.6574 - val_recall: 0.8342\
Epoch 20/40\
 - 555s - loss: 0.2692 - acc: 0.8843 - f1: 0.9233 - precision: 0.8848 - recall: 0.9674 - val_loss: 0.7527 - val_acc: 0.6960 - val_f1: 0.7416 - val_precision: 0.6497 - val_recall: 0.8724\
Epoch 21/40\
 - 559s - loss: 0.2574 - acc: 0.8886 - f1: 0.9259 - precision: 0.8895 - recall: 0.9674 - val_loss: 0.7543 - val_acc: 0.6990 - val_f1: 0.7396 - val_precision: 0.6583 - val_recall: 0.8557\
Epoch 22/40\
 - 560s - loss: 0.2441 - acc: 0.8943 - f1: 0.9296 - precision: 0.8949 - recall: 0.9690 - val_loss: 0.7725 - val_acc: 0.6950 - val_f1: 0.7395 - val_precision: 0.6526 - val_recall: 0.8663\
Epoch 23/40\
 - 554s - loss: 0.2311 - acc: 0.8986 - f1: 0.9322 - precision: 0.8994 - recall: 0.9696 - val_loss: 0.8831 - val_acc: 0.6960 - val_f1: 0.7439 - val_precision: 0.6481 - val_recall: 0.8829\
Epoch 24/40\
 - 560s - loss: 0.2205 - acc: 0.9037 - f1: 0.9355 - precision: 0.9043 - recall: 0.9709 - val_loss: 0.9198 - val_acc: 0.6850 - val_f1: 0.7290 - val_precision: 0.6430 - val_recall: 0.8485\
Epoch 25/40\
 - 554s - loss: 0.2082 - acc: 0.9085 - f1: 0.9385 - precision: 0.9093 - recall: 0.9716 - val_loss: 0.9831 - val_acc: 0.6900 - val_f1: 0.7346 - val_precision: 0.6464 - val_recall: 0.8585\
Epoch 26/40\
 - 554s - loss: 0.1966 - acc: 0.9132 - f1: 0.9415 - precision: 0.9152 - recall: 0.9710 - val_loss: 0.9823 - val_acc: 0.6920 - val_f1: 0.7326 - val_precision: 0.6520 - val_recall: 0.8459\
Epoch 27/40\
 - 555s - loss: 0.1875 - acc: 0.9173 - f1: 0.9441 - precision: 0.9195 - recall: 0.9717 - val_loss: 1.0405 - val_acc: 0.7020 - val_f1: 0.7480 - val_precision: 0.6524 - val_recall: 0.8853\
Epoch 28/40\
 - 554s - loss: 0.1754 - acc: 0.9223 - f1: 0.9474 - precision: 0.9246 - recall: 0.9729 - val_loss: 1.0929 - val_acc: 0.6880 - val_f1: 0.7332 - val_precision: 0.6471 - val_recall: 0.8575\
Epoch 29/40\
 - 554s - loss: 0.1656 - acc: 0.9268 - f1: 0.9503 - precision: 0.9296 - recall: 0.9735 - val_loss: 1.1130 - val_acc: 0.6840 - val_f1: 0.7268 - val_precision: 0.6437 - val_recall: 0.8419\
Epoch 30/40\
 - 554s - loss: 0.1577 - acc: 0.9301 - f1: 0.9526 - precision: 0.9333 - recall: 0.9741 - val_loss: 1.1233 - val_acc: 0.6970 - val_f1: 0.7332 - val_precision: 0.6584 - val_recall: 0.8349\
Epoch 31/40\
 - 556s - loss: 0.1481 - acc: 0.9343 - f1: 0.9552 - precision: 0.9384 - recall: 0.9739 - val_loss: 1.0820 - val_acc: 0.6970 - val_f1: 0.7295 - val_precision: 0.6628 - val_recall: 0.8191\
Epoch 32/40\
 - 554s - loss: 0.1413 - acc: 0.9370 - f1: 0.9570 - precision: 0.9420 - recall: 0.9737 - val_loss: 1.2014 - val_acc: 0.7010 - val_f1: 0.7368 - val_precision: 0.6661 - val_recall: 0.8333\
Epoch 33/40\
 - 554s - loss: 0.1324 - acc: 0.9416 - f1: 0.9600 - precision: 0.9464 - recall: 0.9751 - val_loss: 1.1224 - val_acc: 0.6960 - val_f1: 0.7303 - val_precision: 0.6619 - val_recall: 0.8236\
Epoch 34/40\
 - 555s - loss: 0.1257 - acc: 0.9447 - f1: 0.9621 - precision: 0.9496 - recall: 0.9760 - val_loss: 1.2210 - val_acc: 0.6940 - val_f1: 0.7226 - val_precision: 0.6653 - val_recall: 0.7985\
Epoch 35/40\
 - 554s - loss: 0.1201 - acc: 0.9468 - f1: 0.9635 - precision: 0.9525 - recall: 0.9759 - val_loss: 1.2703 - val_acc: 0.6920 - val_f1: 0.7300 - val_precision: 0.6564 - val_recall: 0.8305\
Epoch 36/40\
 - 554s - loss: 0.1131 - acc: 0.9504 - f1: 0.9660 - precision: 0.9561 - recall: 0.9770 - val_loss: 1.1991 - val_acc: 0.7010 - val_f1: 0.7276 - val_precision: 0.6691 - val_recall: 0.8052\
Epoch 37/40\
 - 557s - loss: 0.1066 - acc: 0.9534 - f1: 0.9679 - precision: 0.9593 - recall: 0.9776 - val_loss: 1.2993 - val_acc: 0.6920 - val_f1: 0.7277 - val_precision: 0.6575 - val_recall: 0.8237\
Epoch 38/40\
 - 555s - loss: 0.1035 - acc: 0.9550 - f1: 0.9689 - precision: 0.9612 - recall: 0.9777 - val_loss: 1.3420 - val_acc: 0.6910 - val_f1: 0.7255 - val_precision: 0.6589 - val_recall: 0.8171\
Epoch 39/40\
 - 554s - loss: 0.0963 - acc: 0.9579 - f1: 0.9710 - precision: 0.9637 - recall: 0.9792 - val_loss: 1.3389 - val_acc: 0.7010 - val_f1: 0.7335 - val_precision: 0.6670 - val_recall: 0.8228\
Epoch 40/40\
 - 555s - loss: 0.0934 - acc: 0.9593 - f1: 0.9719 - precision: 0.9661 - recall: 0.9786 - val_loss: 1.3371 - val_acc: 0.7050 - val_f1: 0.7439 - val_precision: 0.6636 - val_recall: 0.8556\
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardirnatural\partightenfactor0

\f0\b \cf0 Loss: 136.74%\
Accuracy: 68.76%\
F1 score: 72.28%\
Precision: 64.42%\
Recall: 83.92%\
\
\
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardirnatural\partightenfactor0

\fs24 \cf0 \ul NETWORK 7
\fs20 \ulnone \
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardirnatural\partightenfactor0

\f1\b0 \cf0 _________________________________________________________________\
Layer (type)                 Output Shape              Param #   \
=================================================================\
lstm_1 (LSTM)                (None, 6, 300)            721200    \
_________________________________________________________________\
lstm_2 (LSTM)                (None, 6, 300)            721200    \
_________________________________________________________________\
global_average_pooling1d_1 ( (None, 300)               0         \
_________________________________________________________________\
dense_1 (Dense)              (None, 1)                 301       \
=================================================================\
Total params: 1,442,701\
Trainable params: 1,442,701\
Non-trainable params: 0\
_________________________________________________________________\
None\
Minibatch size: 30\
Timesteps: 6\
Train on 109810 samples, validate on 1000 samples\
Epoch 1/19\
 - 419s - loss: 0.5067 - acc: 0.7714 - f1: 0.8572 - precision: 0.7782 - recall: 0.9619 - val_loss: 0.6986 - val_acc: 0.6120 - val_f1: 0.7108 - val_precision: 0.5696 - val_recall: 0.9618\
Epoch 2/19\
 - 414s - loss: 0.4687 - acc: 0.7925 - f1: 0.8690 - precision: 0.7948 - recall: 0.9645 - val_loss: 0.6680 - val_acc: 0.6540 - val_f1: 0.7315 - val_precision: 0.6004 - val_recall: 0.9519\
Epoch 3/19\
 - 437s - loss: 0.4507 - acc: 0.8025 - f1: 0.8745 - precision: 0.8043 - recall: 0.9638 - val_loss: 0.6439 - val_acc: 0.6640 - val_f1: 0.7361 - val_precision: 0.6075 - val_recall: 0.9499\
Epoch 4/19\
 - 409s - loss: 0.4346 - acc: 0.8124 - f1: 0.8798 - precision: 0.8135 - recall: 0.9633 - val_loss: 0.6400 - val_acc: 0.6630 - val_f1: 0.7318 - val_precision: 0.6097 - val_recall: 0.9310\
Epoch 5/19\
 - 410s - loss: 0.4206 - acc: 0.8201 - f1: 0.8843 - precision: 0.8200 - recall: 0.9650 - val_loss: 0.6373 - val_acc: 0.6660 - val_f1: 0.7381 - val_precision: 0.6097 - val_recall: 0.9521\
Epoch 6/19\
 - 1650s - loss: 0.4084 - acc: 0.8262 - f1: 0.8879 - precision: 0.8253 - recall: 0.9659 - val_loss: 0.6589 - val_acc: 0.6710 - val_f1: 0.7406 - val_precision: 0.6145 - val_recall: 0.9504\
Epoch 7/19\
 - 504s - loss: 0.3969 - acc: 0.8315 - f1: 0.8911 - precision: 0.8310 - recall: 0.9654 - val_loss: 0.6007 - val_acc: 0.6810 - val_f1: 0.7410 - val_precision: 0.6254 - val_recall: 0.9245\
Epoch 8/19\
 - 497s - loss: 0.3847 - acc: 0.8368 - f1: 0.8941 - precision: 0.8358 - recall: 0.9660 - val_loss: 0.5982 - val_acc: 0.6850 - val_f1: 0.7426 - val_precision: 0.6299 - val_recall: 0.9193\
Epoch 9/19\
 - 478s - loss: 0.3721 - acc: 0.8423 - f1: 0.8974 - precision: 0.8415 - recall: 0.9659 - val_loss: 0.6525 - val_acc: 0.6820 - val_f1: 0.7425 - val_precision: 0.6283 - val_recall: 0.9241\
Epoch 10/19\
 - 853s - loss: 0.3600 - acc: 0.8485 - f1: 0.9009 - precision: 0.8475 - recall: 0.9660 - val_loss: 0.6325 - val_acc: 0.6810 - val_f1: 0.7346 - val_precision: 0.6318 - val_recall: 0.8945\
Epoch 11/19\
 - 513s - loss: 0.3477 - acc: 0.8531 - f1: 0.9037 - precision: 0.8528 - recall: 0.9655 - val_loss: 0.5917 - val_acc: 0.6970 - val_f1: 0.7447 - val_precision: 0.6450 - val_recall: 0.8948\
Epoch 12/19\
 - 535s - loss: 0.3333 - acc: 0.8586 - f1: 0.9070 - precision: 0.8585 - recall: 0.9653 - val_loss: 0.6530 - val_acc: 0.6930 - val_f1: 0.7453 - val_precision: 0.6394 - val_recall: 0.9075\
Epoch 13/19\
 - 531s - loss: 0.3202 - acc: 0.8650 - f1: 0.9107 - precision: 0.8650 - recall: 0.9658 - val_loss: 0.7098 - val_acc: 0.7020 - val_f1: 0.7511 - val_precision: 0.6455 - val_recall: 0.9121\
Epoch 14/19\
 - 447s - loss: 0.3066 - acc: 0.8705 - f1: 0.9142 - precision: 0.8706 - recall: 0.9663 - val_loss: 0.6609 - val_acc: 0.7050 - val_f1: 0.7473 - val_precision: 0.6570 - val_recall: 0.8855\
Epoch 15/19\
 - 450s - loss: 0.2910 - acc: 0.8773 - f1: 0.9182 - precision: 0.8774 - recall: 0.9668 - val_loss: 0.6741 - val_acc: 0.6890 - val_f1: 0.7351 - val_precision: 0.6430 - val_recall: 0.8725\
Epoch 16/19\
 - 437s - loss: 0.2764 - acc: 0.8832 - f1: 0.9218 - precision: 0.8840 - recall: 0.9666 - val_loss: 0.7244 - val_acc: 0.6980 - val_f1: 0.7397 - val_precision: 0.6510 - val_recall: 0.8714\
Epoch 17/19\
 - 455s - loss: 0.2627 - acc: 0.8887 - f1: 0.9252 - precision: 0.8898 - recall: 0.9668 - val_loss: 0.7932 - val_acc: 0.6970 - val_f1: 0.7473 - val_precision: 0.6426 - val_recall: 0.9069\
Epoch 18/19\
 - 435s - loss: 0.2471 - acc: 0.8942 - f1: 0.9287 - precision: 0.8962 - recall: 0.9670 - val_loss: 0.7540 - val_acc: 0.6790 - val_f1: 0.7274 - val_precision: 0.6319 - val_recall: 0.8702\
Epoch 19/19\
 - 447s - loss: 0.2323 - acc: 0.8997 - f1: 0.9321 - precision: 0.9029 - recall: 0.9664 - val_loss: 0.8092 - val_acc: 0.6860 - val_f1: 0.7334 - val_precision: 0.6397 - val_recall: 0.8750
\f0\b \
Loss: 82.60%\
Accuracy: 69.33%\
F1 score: 74.00%\
Precision: 63.65%\
Recall: 90.00%
\f1\b0 \
}