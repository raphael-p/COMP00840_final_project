{\rtf1\ansi\ansicpg1252\cocoartf1671\cocoasubrtf400
{\fonttbl\f0\fswiss\fcharset0 Helvetica-Bold;\f1\fswiss\fcharset0 Helvetica;}
{\colortbl;\red255\green255\blue255;}
{\*\expandedcolortbl;;}
\paperw11900\paperh16840\margl1440\margr1440\vieww27240\viewh16580\viewkind0
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardirnatural\partightenfactor0

\f0\b\fs24 \cf0 \ul \ulc0 NETWORK 6\ulnone : FINAL NETWORK
\f1\b0\fs20 \
__________________________________________________________________________________________________\
Layer (type)                    Output Shape         Param #     Connected to                     \
==================================================================================================\
claim_1 (InputLayer)            (None, 50)           0                                            \
__________________________________________________________________________________________________\
evidence_1 (InputLayer)         (None, 200)          0                                            \
__________________________________________________________________________________________________\
claim_2 (Embedding)             (None, 50, 50)       1023300     claim_1[0][0]                    \
__________________________________________________________________________________________________\
evidence_2 (Embedding)          (None, 200, 50)      2426800     evidence_1[0][0]                 \
__________________________________________________________________________________________________\
claim_3_encoding (Bidirectional (None, 50, 50)       15200       claim_2[0][0]                    \
__________________________________________________________________________________________________\
evidence_3_encoding (Bidirectio (None, 200, 50)      15200       evidence_2[0][0]                 \
__________________________________________________________________________________________________\
claim_4_attention (Dense)       (None, 50, 50)       2550        claim_3_encoding[0][0]           \
__________________________________________________________________________________________________\
evidence_4_attention (Dense)    (None, 200, 50)      2550        evidence_3_encoding[0][0]        \
__________________________________________________________________________________________________\
claim_5 (Multiply)              (None, 50, 50)       0           claim_3_encoding[0][0]           \
                                                                 claim_4_attention[0][0]          \
__________________________________________________________________________________________________\
evidence_5 (Multiply)           (None, 200, 50)      0           evidence_3_encoding[0][0]        \
                                                                 evidence_4_attention[0][0]       \
__________________________________________________________________________________________________\
claim_6_sum (Lambda)            (None, 50)           0           claim_5[0][0]                    \
__________________________________________________________________________________________________\
evidence_6_sum (Lambda)         (None, 50)           0           evidence_5[0][0]                 \
__________________________________________________________________________________________________\
claim_7 (Reshape)               (None, 1, 50)        0           claim_6_sum[0][0]                \
__________________________________________________________________________________________________\
evidence_7 (Reshape)            (None, 1, 50)        0           evidence_6_sum[0][0]             \
__________________________________________________________________________________________________\
claim_evi_1 (Concatenate)       (None, 2, 50)        0           claim_7[0][0]                    \
                                                                 evidence_7[0][0]                 \
__________________________________________________________________________________________________\
claim_evi_2_encoding (Bidirecti (None, 2, 50)        15200       claim_evi_1[0][0]                \
__________________________________________________________________________________________________\
claim_evi_3_attention (Dense)   (None, 2, 50)        2550        claim_evi_2_encoding[0][0]       \
__________________________________________________________________________________________________\
claim_evi_4 (Multiply)          (None, 2, 50)        0           claim_evi_2_encoding[0][0]       \
                                                                 claim_evi_3_attention[0][0]      \
__________________________________________________________________________________________________\
claim_evi_5_sum (Lambda)        (None, 50)           0           claim_evi_4[0][0]                \
__________________________________________________________________________________________________\
out (Dense)                     (None, 1)            51          claim_evi_5_sum[0][0]            \
==================================================================================================\
Total params: 3,503,401\
Trainable params: 53,301\
Non-trainable params: 3,450,100\
__________________________________________________________________________________________________\
None\
Minibatch size: 30\
Train on 98514 samples, validate on 500 samples\
Epoch 1/10\
 - 2613s - loss: 0.6063 - acc: 0.7006 - f1: 0.8203 - precision: 0.7031 - recall: 0.9936 - val_loss: 0.5649 - val_acc: 0.6880 - val_f1: 0.8120 - val_precision: 0.6880 - val_recall: 1.0000\
Epoch 2/10\
 - 2543s - loss: 0.5590 - acc: 0.7286 - f1: 0.8295 - precision: 0.7368 - recall: 0.9580 - val_loss: 0.4904 - val_acc: 0.7900 - val_f1: 0.8609 - val_precision: 0.7815 - val_recall: 0.9662\
Epoch 3/10\
 - 2537s - loss: 0.5166 - acc: 0.7665 - f1: 0.8493 - precision: 0.7697 - recall: 0.9542 - val_loss: 0.4727 - val_acc: 0.7940 - val_f1: 0.8602 - val_precision: 0.7993 - val_recall: 0.9387\
Epoch 4/10\
 - 2540s - loss: 0.4967 - acc: 0.7780 - f1: 0.8562 - precision: 0.7777 - recall: 0.9591 - val_loss: 0.4529 - val_acc: 0.8120 - val_f1: 0.8733 - val_precision: 0.8032 - val_recall: 0.9636\
Epoch 5/10\
 - 2560s - loss: 0.4874 - acc: 0.7826 - f1: 0.8586 - precision: 0.7817 - recall: 0.9589 - val_loss: 0.4402 - val_acc: 0.8080 - val_f1: 0.8713 - val_precision: 0.7960 - val_recall: 0.9688\
Epoch 6/10\
 - 2539s - loss: 0.4801 - acc: 0.7874 - f1: 0.8612 - precision: 0.7863 - recall: 0.9583 - val_loss: 0.4470 - val_acc: 0.7980 - val_f1: 0.8591 - val_precision: 0.8131 - val_recall: 0.9163\
Epoch 7/10\
 - 2537s - loss: 0.4757 - acc: 0.7891 - f1: 0.8620 - precision: 0.7884 - recall: 0.9572 - val_loss: 0.4252 - val_acc: 0.8140 - val_f1: 0.8723 - val_precision: 0.8143 - val_recall: 0.9461\
Epoch 8/10\
 - 2539s - loss: 0.4715 - acc: 0.7914 - f1: 0.8632 - precision: 0.7902 - recall: 0.9575 - val_loss: 0.4297 - val_acc: 0.8200 - val_f1: 0.8788 - val_precision: 0.8082 - val_recall: 0.9693\
Epoch 9/10\
 - 2538s - loss: 0.4680 - acc: 0.7931 - f1: 0.8643 - precision: 0.7918 - recall: 0.9579 - val_loss: 0.4156 - val_acc: 0.8120 - val_f1: 0.8709 - val_precision: 0.8112 - val_recall: 0.9455\
Epoch 10/10\
 - 2536s - loss: 0.4643 - acc: 0.7956 - f1: 0.8658 - precision: 0.7937 - recall: 0.9584 - val_loss: 0.4156 - val_acc: 0.8180 - val_f1: 0.8769 - val_precision: 0.8088 - val_recall: 0.9635\

\f0\b Loss: 45.09%\
Accuracy: 80.51%\
F1 score: 87.17%\
Precision: 80.54%\
Recall: 95.57%
\fs24 \ul \
\
\
NETWORK 5\ulnone : Complete Rework, small test
\f1\b0\fs20 \
__________________________________________________________________________________________________\
Layer (type)                    Output Shape         Param #     Connected to                     \
==================================================================================================\
claim_1 (InputLayer)            (None, 50)           0                                            \
__________________________________________________________________________________________________\
evidence_1 (InputLayer)         (None, 200)          0                                            \
__________________________________________________________________________________________________\
claim_2 (Embedding)             (None, 50, 50)       1023300     claim_1[0][0]                    \
__________________________________________________________________________________________________\
evidence_2 (Embedding)          (None, 200, 50)      2426800     evidence_1[0][0]                 \
__________________________________________________________________________________________________\
claim_3_encoding (Bidirectional (None, 50, 50)       15200       claim_2[0][0]                    \
__________________________________________________________________________________________________\
evidence_3_encoding (Bidirectio (None, 200, 50)      15200       evidence_2[0][0]                 \
__________________________________________________________________________________________________\
claim_4_attention (Dense)       (None, 50, 50)       2550        claim_3_encoding[0][0]           \
__________________________________________________________________________________________________\
evidence_4_attention (Dense)    (None, 200, 50)      2550        evidence_3_encoding[0][0]        \
__________________________________________________________________________________________________\
claim_5 (Multiply)              (None, 50, 50)       0           claim_3_encoding[0][0]           \
                                                                 claim_4_attention[0][0]          \
__________________________________________________________________________________________________\
evidence_5 (Multiply)           (None, 200, 50)      0           evidence_3_encoding[0][0]        \
                                                                 evidence_4_attention[0][0]       \
__________________________________________________________________________________________________\
claim_6_sum (Lambda)            (None, 50)           0           claim_5[0][0]                    \
__________________________________________________________________________________________________\
evidence_6_sum (Lambda)         (None, 50)           0           evidence_5[0][0]                 \
__________________________________________________________________________________________________\
claim_7 (Reshape)               (None, 1, 50)        0           claim_6_sum[0][0]                \
__________________________________________________________________________________________________\
evidence_7 (Reshape)            (None, 1, 50)        0           evidence_6_sum[0][0]             \
__________________________________________________________________________________________________\
claim_evi_1 (Concatenate)       (None, 2, 50)        0           claim_7[0][0]                    \
                                                                 evidence_7[0][0]                 \
__________________________________________________________________________________________________\
claim_evi_2_encoding (Bidirecti (None, 2, 50)        15200       claim_evi_1[0][0]                \
__________________________________________________________________________________________________\
claim_evi_3_attention (Dense)   (None, 2, 50)        2550        claim_evi_2_encoding[0][0]       \
__________________________________________________________________________________________________\
claim_evi_4 (Multiply)          (None, 2, 50)        0           claim_evi_2_encoding[0][0]       \
                                                                 claim_evi_3_attention[0][0]      \
__________________________________________________________________________________________________\
claim_evi_5_sum (Lambda)        (None, 50)           0           claim_evi_4[0][0]                \
__________________________________________________________________________________________________\
out (Dense)                     (None, 1)            51          claim_evi_5_sum[0][0]            \
==================================================================================================\
Total params: 3,503,401\
Trainable params: 53,301\
Non-trainable params: 3,450,100\
__________________________________________________________________________________________________\
None\
Minibatch size: 30\
Train on 98514 samples, validate on 500 samples\
Epoch 1/1\
 - 2674s - loss: 0.6005 - acc: 0.7027 - f1: 0.8217 - precision: 0.7046 - recall: 0.9947 - val_loss: 0.5358 - val_acc: 0.7500 - val_f1: 0.8357 - val_precision: 0.7647 - val_recall: 0.9333\

\f0\b Loss: 55.55%\
Accuracy: 73.62%\
F1 score: 83.04%\
Precision: 75.11%\
Recall: 93.55%
\fs24 \ul \
\
\
NETWORK 4\ulnone : Full training FAILED
\f1\b0\fs20 \
__________________________________________________________________________________________________\
Layer (type)                    Output Shape         Param #     Connected to                     \
==================================================================================================\
claim_1 (InputLayer)            (None, 25, 50)       0                                            \
__________________________________________________________________________________________________\
evidence_1 (InputLayer)         (None, 100, 50)      0                                            \
__________________________________________________________________________________________________\
claim_2_encoding (Bidirectional (None, 25, 100)      40400       claim_1[0][0]                    \
__________________________________________________________________________________________________\
evidence_2_encoding (Bidirectio (None, 100, 100)     40400       evidence_1[0][0]                 \
__________________________________________________________________________________________________\
claim_3_attention (Dense)       (None, 25, 1)        101         claim_2_encoding[0][0]           \
__________________________________________________________________________________________________\
time_distributed_1 (TimeDistrib (None, 100, 1)       101         evidence_2_encoding[0][0]        \
__________________________________________________________________________________________________\
claim_4 (Flatten)               (None, 25)           0           claim_3_attention[0][0]          \
__________________________________________________________________________________________________\
evidence_4 (Flatten)            (None, 100)          0           time_distributed_1[0][0]         \
__________________________________________________________________________________________________\
claim_5 (Activation)            (None, 25)           0           claim_4[0][0]                    \
__________________________________________________________________________________________________\
evidence_5 (Activation)         (None, 100)          0           evidence_4[0][0]                 \
__________________________________________________________________________________________________\
claim_6 (RepeatVector)          (None, 100, 25)      0           claim_5[0][0]                    \
__________________________________________________________________________________________________\
evidence_6 (RepeatVector)       (None, 100, 100)     0           evidence_5[0][0]                 \
__________________________________________________________________________________________________\
claim_7 (Permute)               (None, 25, 100)      0           claim_6[0][0]                    \
__________________________________________________________________________________________________\
evidence_7 (Permute)            (None, 100, 100)     0           evidence_6[0][0]                 \
__________________________________________________________________________________________________\
claim_8 (Multiply)              (None, 25, 100)      0           claim_2_encoding[0][0]           \
                                                                 claim_7[0][0]                    \
__________________________________________________________________________________________________\
evidence_8 (Multiply)           (None, 100, 100)     0           evidence_2_encoding[0][0]        \
                                                                 evidence_7[0][0]                 \
__________________________________________________________________________________________________\
claim_9_sum (Lambda)            (None, 100)          0           claim_8[0][0]                    \
__________________________________________________________________________________________________\
evidence_9_sum (Lambda)         (None, 100)          0           evidence_8[0][0]                 \
__________________________________________________________________________________________________\
claim_evidence_1 (Concatenate)  (None, 200)          0           claim_9_sum[0][0]                \
                                                                 evidence_9_sum[0][0]             \
__________________________________________________________________________________________________\
claim_evidence_2 (Dense)        (None, 1)            201         claim_evidence_1[0][0]           \
==================================================================================================\
Total params: 81,203\
Trainable params: 81,203\
Non-trainable params: 0\
__________________________________________________________________________________________________\
None\
Minibatch size: 30\
Evidence size: 100 tokens\
Claim size: 25 tokens\
Train on 109810 samples, validate on 500 samples\
Epoch 1/20\
 - 1613s - loss: 0.5828 - acc: 0.7288 - f1: 0.8406 - precision: 0.7289 - recall: 0.9999 - val_loss: 0.8360 - val_acc: 0.4900 - val_f1: 0.6546 - val_precision: 0.4900 - val_recall: 1.0000\
Epoch 2/20\
 - 1583s - loss: 0.5805 - acc: 0.7288 - f1: 0.8406 - precision: 0.7288 - recall: 1.0000 - val_loss: 0.7997 - val_acc: 0.4900 - val_f1: 0.6546 - val_precision: 0.4900 - val_recall: 1.0000\
Epoch 3/20\
 - 1721s - loss: 0.5797 - acc: 0.7288 - f1: 0.8407 - precision: 0.7288 - recall: 1.0000 - val_loss: 0.8153 - val_acc: 0.4900 - val_f1: 0.6546 - val_precision: 0.4900 - val_recall: 1.0000\
Epoch 4/20\
 - 1829s - loss: 0.5791 - acc: 0.7288 - f1: 0.8406 - precision: 0.7288 - recall: 1.0000 - val_loss: 0.8088 - val_acc: 0.4900 - val_f1: 0.6546 - val_precision: 0.4900 - val_recall: 1.0000\
Epoch 5/20\
 - 1807s - loss: 0.5787 - acc: 0.7288 - f1: 0.8408 - precision: 0.7289 - recall: 0.9999 - val_loss: 0.7866 - val_acc: 0.4900 - val_f1: 0.6546 - val_precision: 0.4900 - val_recall: 1.0000\
Epoch 6/20\
 - 1552s - loss: 0.5781 - acc: 0.7289 - f1: 0.8405 - precision: 0.7289 - recall: 0.9999 - val_loss: 0.8055 - val_acc: 0.4900 - val_f1: 0.6546 - val_precision: 0.4900 - val_recall: 1.0000\
Epoch 7/20\
 - 1394s - loss: 0.5771 - acc: 0.7289 - f1: 0.8405 - precision: 0.7290 - recall: 0.9996 - val_loss: 0.8378 - val_acc: 0.4900 - val_f1: 0.6546 - val_precision: 0.4900 - val_recall: 1.0000\
Epoch 8/20\
 - 1462s - loss: 0.5764 - acc: 0.7292 - f1: 0.8406 - precision: 0.7293 - recall: 0.9993 - val_loss: 0.8251 - val_acc: 0.4900 - val_f1: 0.6546 - val_precision: 0.4900 - val_recall: 1.0000\
Epoch 9/20\
 - 1409s - loss: 0.5758 - acc: 0.7291 - f1: 0.8406 - precision: 0.7294 - recall: 0.9989 - val_loss: 0.8103 - val_acc: 0.4900 - val_f1: 0.6546 - val_precision: 0.4900 - val_recall: 1.0000\
Epoch 10/20\
 - 1433s - loss: 0.5752 - acc: 0.7294 - f1: 0.8408 - precision: 0.7295 - recall: 0.9992 - val_loss: 0.7999 - val_acc: 0.4900 - val_f1: 0.6546 - val_precision: 0.4900 - val_recall: 1.0000\
Epoch 11/20\
 - 1437s - loss: 0.5746 - acc: 0.7292 - f1: 0.8405 - precision: 0.7297 - recall: 0.9981 - val_loss: 0.8359 - val_acc: 0.4900 - val_f1: 0.6546 - val_precision: 0.4900 - val_recall: 1.0000\
Epoch 12/20\
 - 1381s - loss: 0.5739 - acc: 0.7294 - f1: 0.8406 - precision: 0.7297 - recall: 0.9986 - val_loss: 0.7995 - val_acc: 0.4960 - val_f1: 0.6573 - val_precision: 0.4931 - val_recall: 1.0000\
Epoch 13/20\
 - 1434s - loss: 0.5732 - acc: 0.7293 - f1: 0.8406 - precision: 0.7299 - recall: 0.9979 - val_loss: 0.7948 - val_acc: 0.4960 - val_f1: 0.6563 - val_precision: 0.4930 - val_recall: 0.9954\
Epoch 14/20\
 - 1405s - loss: 0.5727 - acc: 0.7296 - f1: 0.8406 - precision: 0.7302 - recall: 0.9976 - val_loss: 0.8119 - val_acc: 0.4940 - val_f1: 0.6565 - val_precision: 0.4923 - val_recall: 1.0000\
Epoch 15/20\
 - 1380s - loss: 0.5722 - acc: 0.7296 - f1: 0.8406 - precision: 0.7302 - recall: 0.9976 - val_loss: 0.7931 - val_acc: 0.4980 - val_f1: 0.6583 - val_precision: 0.4943 - val_recall: 1.0000\
Epoch 16/20\
 - 1492s - loss: 0.5712 - acc: 0.7295 - f1: 0.8405 - precision: 0.7304 - recall: 0.9967 - val_loss: 0.8035 - val_acc: 0.4940 - val_f1: 0.6565 - val_precision: 0.4920 - val_recall: 1.0000\
Epoch 17/20\
 - 1410s - loss: 0.5711 - acc: 0.7296 - f1: 0.8405 - precision: 0.7304 - recall: 0.9967 - val_loss: 0.8123 - val_acc: 0.4920 - val_f1: 0.6555 - val_precision: 0.4910 - val_recall: 1.0000\
Epoch 18/20\
 - 1429s - loss: 0.5703 - acc: 0.7296 - f1: 0.8404 - precision: 0.7306 - recall: 0.9965 - val_loss: 0.8082 - val_acc: 0.4980 - val_f1: 0.6583 - val_precision: 0.4943 - val_recall: 1.0000\
Epoch 19/20\
 - 1473s - loss: 0.5699 - acc: 0.7296 - f1: 0.8403 - precision: 0.7309 - recall: 0.9956 - val_loss: 0.8350 - val_acc: 0.4940 - val_f1: 0.6556 - val_precision: 0.4924 - val_recall: 0.9960\
Epoch 20/20\
 - 1413s - loss: 0.5691 - acc: 0.7295 - f1: 0.8402 - precision: 0.7311 - recall: 0.9949 - val_loss: 0.7952 - val_acc: 0.4980 - val_f1: 0.6583 - val_precision: 0.4943 - val_recall: 1.0000\

\f0\b Loss: 79.17%\
Accuracy: 50.31%\
F1 score: 66.14%\
Precision: 50.16%\
Recall: 99.34%\
\
\

\fs24 \ul NETWORK 3\ulnone : Dropout test (small database) FAILED
\f1\b0\fs20 \
__________________________________________________________________________________________________\
Layer (type)                    Output Shape         Param #     Connected to                     \
==================================================================================================\
claim_1 (InputLayer)            (None, 25, 50)       0                                            \
__________________________________________________________________________________________________\
evidence_1 (InputLayer)         (None, 200, 50)      0                                            \
__________________________________________________________________________________________________\
claim_2_encoding (Bidirectional (None, 25, 100)      40400       claim_1[0][0]                    \
__________________________________________________________________________________________________\
evidence_2_encoding (Bidirectio (None, 200, 100)     40400       evidence_1[0][0]                 \
__________________________________________________________________________________________________\
claim_3_attention (Dense)       (None, 25, 1)        101         claim_2_encoding[0][0]           \
__________________________________________________________________________________________________\
time_distributed_1 (TimeDistrib (None, 200, 1)       101         evidence_2_encoding[0][0]        \
__________________________________________________________________________________________________\
claim_4 (Flatten)               (None, 25)           0           claim_3_attention[0][0]          \
__________________________________________________________________________________________________\
evidence_4 (Flatten)            (None, 200)          0           time_distributed_1[0][0]         \
__________________________________________________________________________________________________\
claim_5 (Activation)            (None, 25)           0           claim_4[0][0]                    \
__________________________________________________________________________________________________\
evidence_5 (Activation)         (None, 200)          0           evidence_4[0][0]                 \
__________________________________________________________________________________________________\
claim_6 (RepeatVector)          (None, 100, 25)      0           claim_5[0][0]                    \
__________________________________________________________________________________________________\
evidence_6 (RepeatVector)       (None, 100, 200)     0           evidence_5[0][0]                 \
__________________________________________________________________________________________________\
claim_7 (Permute)               (None, 25, 100)      0           claim_6[0][0]                    \
__________________________________________________________________________________________________\
evidence_7 (Permute)            (None, 200, 100)     0           evidence_6[0][0]                 \
__________________________________________________________________________________________________\
claim_8 (Multiply)              (None, 25, 100)      0           claim_2_encoding[0][0]           \
                                                                 claim_7[0][0]                    \
__________________________________________________________________________________________________\
evidence_8 (Multiply)           (None, 200, 100)     0           evidence_2_encoding[0][0]        \
                                                                 evidence_7[0][0]                 \
__________________________________________________________________________________________________\
claim_9_sum (Lambda)            (None, 100)          0           claim_8[0][0]                    \
__________________________________________________________________________________________________\
evidence_9_sum (Lambda)         (None, 100)          0           evidence_8[0][0]                 \
__________________________________________________________________________________________________\
claim_evidence_1 (Concatenate)  (None, 200)          0           claim_9_sum[0][0]                \
                                                                 evidence_9_sum[0][0]             \
__________________________________________________________________________________________________\
claim_evidence_2 (Dense)        (None, 1)            201         claim_evidence_1[0][0]           \
==================================================================================================\
Total params: 81,203\
Trainable params: 81,203\
Non-trainable params: 0\
__________________________________________________________________________________________________\
None\
Minibatch size: 100\
Evidence size: 200 tokens\
Claim size: 25 tokens\
Train on 7407 samples, validate on 500 samples\
Epoch 1/3\
 - 101s - loss: 0.5946 - acc: 0.7257 - f1: 0.8401 - precision: 0.7272 - recall: 0.9970 - val_loss: 0.7995 - val_acc: 0.4900 - val_f1: 0.6563 - val_precision: 0.4900 - val_recall: 1.0000\
Epoch 2/3\
 - 88s - loss: 0.5869 - acc: 0.7269 - f1: 0.8408 - precision: 0.7269 - recall: 1.0000 - val_loss: 0.8269 - val_acc: 0.4900 - val_f1: 0.6563 - val_precision: 0.4900 - val_recall: 1.0000\
Epoch 3/3\
 - 89s - loss: 0.5855 - acc: 0.7269 - f1: 0.8408 - precision: 0.7269 - recall: 1.0000 - val_loss: 0.8261 - val_acc: 0.4900 - val_f1: 0.6563 - val_precision: 0.4900 - val_recall: 1.0000\

\f0\b Loss: 81.76%\
Accuracy: 50.07%\
F1 score: 66.07%\
Precision: 50.07%\
Recall: 99.85%\
\
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardirnatural\partightenfactor0
\cf0 \

\fs24 \ul NETWORK 2\ulnone : TimeDistributed test (small database) FAILED
\f1\b0\fs20 \
__________________________________________________________________________________________________\
Layer (type)                    Output Shape         Param #     Connected to                     \
==================================================================================================\
claim_1 (InputLayer)            (None, 25, 50)       0                                            \
__________________________________________________________________________________________________\
evidence_1 (InputLayer)         (None, 200, 50)      0                                            \
__________________________________________________________________________________________________\
claim_2_encoding (Bidirectional (None, 25, 100)      40400       claim_1[0][0]                    \
__________________________________________________________________________________________________\
evidence_2_encoding (Bidirectio (None, 200, 100)     40400       evidence_1[0][0]                 \
__________________________________________________________________________________________________\
time_distributed_1 (TimeDistrib (None, 25, 1)        101         claim_2_encoding[0][0]           \
__________________________________________________________________________________________________\
time_distributed_2 (TimeDistrib (None, 200, 1)       101         evidence_2_encoding[0][0]        \
__________________________________________________________________________________________________\
claim_4 (Flatten)               (None, 25)           0           time_distributed_1[0][0]         \
__________________________________________________________________________________________________\
evidence_4 (Flatten)            (None, 200)          0           time_distributed_2[0][0]         \
__________________________________________________________________________________________________\
claim_5 (Activation)            (None, 25)           0           claim_4[0][0]                    \
__________________________________________________________________________________________________\
evidence_5 (Activation)         (None, 200)          0           evidence_4[0][0]                 \
__________________________________________________________________________________________________\
claim_6 (RepeatVector)          (None, 100, 25)      0           claim_5[0][0]                    \
__________________________________________________________________________________________________\
evidence_6 (RepeatVector)       (None, 100, 200)     0           evidence_5[0][0]                 \
__________________________________________________________________________________________________\
claim_7 (Permute)               (None, 25, 100)      0           claim_6[0][0]                    \
__________________________________________________________________________________________________\
evidence_7 (Permute)            (None, 200, 100)     0           evidence_6[0][0]                 \
__________________________________________________________________________________________________\
claim_8 (Multiply)              (None, 25, 100)      0           claim_2_encoding[0][0]           \
                                                                 claim_7[0][0]                    \
__________________________________________________________________________________________________\
evidence_8 (Multiply)           (None, 200, 100)     0           evidence_2_encoding[0][0]        \
                                                                 evidence_7[0][0]                 \
__________________________________________________________________________________________________\
claim_9_sum (Lambda)            (None, 100)          0           claim_8[0][0]                    \
__________________________________________________________________________________________________\
evidence_9_sum (Lambda)         (None, 100)          0           evidence_8[0][0]                 \
__________________________________________________________________________________________________\
claim_evidence_1 (Concatenate)  (None, 200)          0           claim_9_sum[0][0]                \
                                                                 evidence_9_sum[0][0]             \
__________________________________________________________________________________________________\
claim_evidence_2 (Dense)        (None, 1)            201         claim_evidence_1[0][0]           \
==================================================================================================\
Total params: 81,203\
Trainable params: 81,203\
Non-trainable params: 0\
__________________________________________________________________________________________________\
None\
Minibatch size: 100\
Evidence size: 200 tokens\
Claim size: 25 tokens\
Train on 7407 samples, validate on 500 samples\
Epoch 1/3\
 - 119s - loss: 0.5904 - acc: 0.7269 - f1: 0.8410 - precision: 0.7269 - recall: 1.0000 - val_loss: 0.7965 - val_acc: 0.4900 - val_f1: 0.6563 - val_precision: 0.4900 - val_recall: 1.0000\
Epoch 2/3\
 - 90s - loss: 0.5843 - acc: 0.7267 - f1: 0.8409 - precision: 0.7268 - recall: 0.9998 - val_loss: 0.7972 - val_acc: 0.4900 - val_f1: 0.6563 - val_precision: 0.4900 - val_recall: 1.0000\
Epoch 3/3\
 - 87s - loss: 0.5820 - acc: 0.7269 - f1: 0.8409 - precision: 0.7269 - recall: 1.0000 - val_loss: 0.8125 - val_acc: 0.4900 - val_f1: 0.6563 - val_precision: 0.4900 - val_recall: 1.0000
\f0\b \
Loss: 80.30%\
Accuracy: 50.07%\
F1 score: 66.07%\
Precision: 50.07%\
Recall: 99.85%\
\
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardirnatural\partightenfactor0

\fs24 \cf0 \ul \ulc0 \
NETWORK 1\ulnone : Initial test (small database) FAILED
\f1\b0\fs20 \
__________________________________________________________________________________________________\
Layer (type)                    Output Shape         Param #     Connected to                     \
==================================================================================================\
claim_1 (InputLayer)            (None, 25, 50)       0                                            \
__________________________________________________________________________________________________\
evidence_1 (InputLayer)         (None, 200, 50)      0                                            \
__________________________________________________________________________________________________\
claim_2_encoding (Bidirectional (None, 25, 100)      40400       claim_1[0][0]                    \
__________________________________________________________________________________________________\
evidence_2_encoding (Bidirectio (None, 200, 100)     40400       evidence_1[0][0]                 \
__________________________________________________________________________________________________\
claim_3_attention (Dense)       (None, 25, 1)        101         claim_2_encoding[0][0]           \
__________________________________________________________________________________________________\
evidence_3_attention (Dense)    (None, 200, 1)       101         evidence_2_encoding[0][0]        \
__________________________________________________________________________________________________\
claim_4 (Flatten)               (None, 25)           0           claim_3_attention[0][0]          \
__________________________________________________________________________________________________\
evidence_4 (Flatten)            (None, 200)          0           evidence_3_attention[0][0]       \
__________________________________________________________________________________________________\
claim_5 (Activation)            (None, 25)           0           claim_4[0][0]                    \
__________________________________________________________________________________________________\
evidence_5 (Activation)         (None, 200)          0           evidence_4[0][0]                 \
__________________________________________________________________________________________________\
claim_6 (RepeatVector)          (None, 100, 25)      0           claim_5[0][0]                    \
__________________________________________________________________________________________________\
evidence_6 (RepeatVector)       (None, 100, 200)     0           evidence_5[0][0]                 \
__________________________________________________________________________________________________\
claim_7 (Permute)               (None, 25, 100)      0           claim_6[0][0]                    \
__________________________________________________________________________________________________\
evidence_7 (Permute)            (None, 200, 100)     0           evidence_6[0][0]                 \
__________________________________________________________________________________________________\
claim_8 (Multiply)              (None, 25, 100)      0           claim_2_encoding[0][0]           \
                                                                 claim_7[0][0]                    \
__________________________________________________________________________________________________\
evidence_8 (Multiply)           (None, 200, 100)     0           evidence_2_encoding[0][0]        \
                                                                 evidence_7[0][0]                 \
__________________________________________________________________________________________________\
claim_9_sum (Lambda)            (None, 100)          0           claim_8[0][0]                    \
__________________________________________________________________________________________________\
evidence_9_sum (Lambda)         (None, 100)          0           evidence_8[0][0]                 \
__________________________________________________________________________________________________\
claim_evidence_1 (Concatenate)  (None, 200)          0           claim_9_sum[0][0]                \
                                                                 evidence_9_sum[0][0]             \
__________________________________________________________________________________________________\
claim_evidence_2 (Dense)        (None, 1)            201         claim_evidence_1[0][0]           \
==================================================================================================\
Total params: 81,203\
Trainable params: 81,203\
Non-trainable params: 0\
__________________________________________________________________________________________________\
None\
Minibatch size: 100\
Evidence size: 200 tokens\
Claim size: 25 tokens\
Train on 7407 samples, validate on 500 samples\
Epoch 1/3\
 - 80s - loss: 0.5933 - acc: 0.7238 - f1: 0.8364 - precision: 0.7282 - recall: 0.9906 - val_loss: 0.7851 - val_acc: 0.4900 - val_f1: 0.6563 - val_precision: 0.4900 - val_recall: 1.0000\
Epoch 2/3\
 - 72s - loss: 0.5853 - acc: 0.7269 - f1: 0.8410 - precision: 0.7270 - recall: 0.9996 - val_loss: 0.8173 - val_acc: 0.4900 - val_f1: 0.6563 - val_precision: 0.4900 - val_recall: 1.0000\
Epoch 3/3\
 - 72s - loss: 0.5820 - acc: 0.7267 - f1: 0.8413 - precision: 0.7268 - recall: 0.9998 - val_loss: 0.8251 - val_acc: 0.4900 - val_f1: 0.6563 - val_precision: 0.4900 - val_recall: 1.0000\

\f0\b Loss: 81.54%\
Accuracy: 50.07%\
F1 score: 66.07%\
Precision: 50.07%\
Recall: 99.85%\
}