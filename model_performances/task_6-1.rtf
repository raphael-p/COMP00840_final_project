{\rtf1\ansi\ansicpg1252\cocoartf1671\cocoasubrtf400
{\fonttbl\f0\fswiss\fcharset0 Helvetica-Bold;\f1\fswiss\fcharset0 Helvetica;}
{\colortbl;\red255\green255\blue255;}
{\*\expandedcolortbl;;}
\paperw11900\paperh16840\margl1440\margr1440\vieww28600\viewh18000\viewkind0
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardirnatural\partightenfactor0

\f0\b\fs24 \cf0 \ul \ulc0 NETWORK 1
\f1\b0\fs20 \ulnone \
_________________________________________________________________\
Layer (type)                 Output Shape              Param #   \
=================================================================\
lstm_1 (LSTM)                (None, 1, 500)            2202000   \
_________________________________________________________________\
lstm_2 (LSTM)                (None, 1, 300)            961200    \
_________________________________________________________________\
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\fi8\pardirnatural\partightenfactor0
\cf0 lstm_3 (LSTM)                (None, 1, 300)            721200    \
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardirnatural\partightenfactor0
\cf0 _________________________________________________________________\
lstm_4 (LSTM)                (None, 1, 300)            721200    \
_________________________________________________________________\
lstm_5 (LSTM)                (None, 300)               721200    \
_________________________________________________________________\
dense_1 (Dense)              (None, 1)                 301       \
=================================================================\
Total params: 5,327,101\
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\ri-12227\pardirnatural\partightenfactor0
\cf0 Trainable params: 5,327,101\
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardirnatural\partightenfactor0
\cf0 Non-trainable params: 0\
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardirnatural\partightenfactor0
\cf0 Minibatch size: 40\
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardirnatural\partightenfactor0
\cf0 _________________________________________________________________\
None\
Train on 139618 samples, validate on 22258 samples\
Epoch 1/10\
 - 923s - loss: 0.4546 - acc: 0.7953 - f1_m: 0.8682 - precision_m: 0.8017 - recall_m: 0.9526 - val_loss: 0.6506 - val_acc: 0.6739 - val_f1_m: 0.7174 - val_precision_m: 0.6089 - val_recall_m: 0.9133\
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardirnatural\partightenfactor0
\cf0 Epoch 2/10\
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardirnatural\partightenfactor0
\cf0  - 848s - loss: 0.3993 - acc: 0.8264 - f1_m: 0.8858 - precision_m: 0.8307 - recall_m: 0.9530 - val_loss: 0.6205 - val_acc: 0.6790 - val_f1_m: 0.7239 - val_precision_m: 0.6088 - val_recall_m: 0.9330\
Epoch 3/10\
 - 846s - loss: 0.3609 - acc: 0.8456 - f1_m: 0.8975 - precision_m: 0.8486 - recall_m: 0.9563 - val_loss: 0.6026 - val_acc: 0.6947 - val_f1_m: 0.7324 - val_precision_m: 0.6230 - val_recall_m: 0.9268\
Epoch 4/10\
 - 840s - loss: 0.3257 - acc: 0.8626 - f1_m: 0.9080 - precision_m: 0.8648 - recall_m: 0.9592 - val_loss: 0.6489 - val_acc: 0.6587 - val_f1_m: 0.7210 - val_precision_m: 0.5903 - val_recall_m: 0.9709\
Epoch 5/10\
 - 843s - loss: 0.2969 - acc: 0.8762 - f1_m: 0.9166 - precision_m: 0.8773 - recall_m: 0.9627 - val_loss: 0.6472 - val_acc: 0.7105 - val_f1_m: 0.7395 - val_precision_m: 0.6404 - val_recall_m: 0.9098\
Epoch 6/10\
 - 842s - loss: 0.2742 - acc: 0.8858 - f1_m: 0.9227 - precision_m: 0.8864 - recall_m: 0.9649 - val_loss: 0.6319 - val_acc: 0.7148 - val_f1_m: 0.7389 - val_precision_m: 0.6467 - val_recall_m: 0.8960\
Epoch 7/10\
 - 842s - loss: 0.2540 - acc: 0.8946 - f1_m: 0.9283 - precision_m: 0.8953 - recall_m: 0.9665 - val_loss: 0.6883 - val_acc: 0.7099 - val_f1_m: 0.7381 - val_precision_m: 0.6404 - val_recall_m: 0.9076\
Epoch 8/10\
 - 840s - loss: 0.2348 - acc: 0.9023 - f1_m: 0.9334 - precision_m: 0.9034 - recall_m: 0.9679 - val_loss: 0.7075 - val_acc: 0.7105 - val_f1_m: 0.7400 - val_precision_m: 0.6407 - val_recall_m: 0.9125\
Epoch 9/10\
 - 841s - loss: 0.2173 - acc: 0.9095 - f1_m: 0.9380 - precision_m: 0.9107 - recall_m: 0.9693 - val_loss: 0.7691 - val_acc: 0.7127 - val_f1_m: 0.7386 - val_precision_m: 0.6450 - val_recall_m: 0.8996\
Epoch 10/10\
 - 842s - loss: 0.2013 - acc: 0.9156 - f1_m: 0.9420 - precision_m: 0.9174 - recall_m: 0.9702 - val_loss: 0.7588 - val_acc: 0.7163 - val_f1_m: 0.7424 - val_precision_m: 0.6492 - val_recall_m: 0.9020\
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardirnatural\partightenfactor0

\f0\b \cf0 Loss: 75.88%\
Accuracy: 71.63%\
F1 score: 74.10%\
Precision: 64.94%\
Recall: 90.17%
\f1\b0 \
\
	\
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardirnatural\partightenfactor0

\f0\b\fs24 \cf0 \ul \ulc0 NETWORK 2
\f1\b0\fs20 \ulnone \
_________________________________________________________________\
Layer (type)                 Output Shape              Param #   \
=================================================================\
lstm_1 (LSTM)                (None, 2, 300)            721200    \
_________________________________________________________________\
lstm_2 (LSTM)                (None, 300)               721200    \
_________________________________________________________________\
dense_1 (Dense)              (None, 1)                 301       \
=================================================================\
Total params: 1,442,701\
Trainable params: 1,442,701\
Non-trainable params: 0\
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardirnatural\partightenfactor0
\cf0 Minibatch size: 40\
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardirnatural\partightenfactor0
\cf0 _________________________________________________________________\
None\
Train on 139618 samples, validate on 22258 samples\
Epoch 1/10\
 - 336s - loss: 0.4471 - acc: 0.7986 - f1_m: 0.8695 - precision_m: 0.8067 - recall_m: 0.9483 - val_loss: 0.6047 - val_acc: 0.6849 - val_f1_m: 0.7138 - val_precision_m: 0.6239 - val_recall_m: 0.8707\
Epoch 2/10\
 - 305s - loss: 0.3935 - acc: 0.8287 - f1_m: 0.8870 - precision_m: 0.8338 - recall_m: 0.9513 - val_loss: 0.5812 - val_acc: 0.6913 - val_f1_m: 0.7230 - val_precision_m: 0.6247 - val_recall_m: 0.8956\
Epoch 3/10\
 - 294s - loss: 0.3617 - acc: 0.8454 - f1_m: 0.8972 - precision_m: 0.8491 - recall_m: 0.9548 - val_loss: 0.6339 - val_acc: 0.6908 - val_f1_m: 0.7283 - val_precision_m: 0.6202 - val_recall_m: 0.9218\
Epoch 4/10\
 - 310s - loss: 0.3349 - acc: 0.8583 - f1_m: 0.9051 - precision_m: 0.8619 - recall_m: 0.9563 - val_loss: 0.5773 - val_acc: 0.7021 - val_f1_m: 0.7269 - val_precision_m: 0.6388 - val_recall_m: 0.8816\
Epoch 5/10\
 - 304s - loss: 0.3098 - acc: 0.8701 - f1_m: 0.9126 - precision_m: 0.8724 - recall_m: 0.9596 - val_loss: 0.6162 - val_acc: 0.6950 - val_f1_m: 0.7334 - val_precision_m: 0.6231 - val_recall_m: 0.9306\
Epoch 6/10\
 - 282s - loss: 0.2884 - acc: 0.8806 - f1_m: 0.9193 - precision_m: 0.8819 - recall_m: 0.9629 - val_loss: 0.6615 - val_acc: 0.6972 - val_f1_m: 0.7348 - val_precision_m: 0.6262 - val_recall_m: 0.9278\
Epoch 7/10\
 - 281s - loss: 0.2686 - acc: 0.8883 - f1_m: 0.9242 - precision_m: 0.8904 - recall_m: 0.9633 - val_loss: 0.6707 - val_acc: 0.7011 - val_f1_m: 0.7345 - val_precision_m: 0.6310 - val_recall_m: 0.9164\
Epoch 8/10\
 - 287s - loss: 0.2510 - acc: 0.8962 - f1_m: 0.9293 - precision_m: 0.8979 - recall_m: 0.9653 - val_loss: 0.7132 - val_acc: 0.6978 - val_f1_m: 0.7321 - val_precision_m: 0.6295 - val_recall_m: 0.9150\
Epoch 9/10\
 - 288s - loss: 0.2337 - acc: 0.9029 - f1_m: 0.9336 - precision_m: 0.9053 - recall_m: 0.9660 - val_loss: 0.7269 - val_acc: 0.7065 - val_f1_m: 0.7354 - val_precision_m: 0.6380 - val_recall_m: 0.9061\
Epoch 10/10\
 - 282s - loss: 0.2176 - acc: 0.9099 - f1_m: 0.9381 - precision_m: 0.9125 - recall_m: 0.9673 - val_loss: 0.7194 - val_acc: 0.7075 - val_f1_m: 0.7323 - val_precision_m: 0.6415 - val_recall_m: 0.8894\
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardirnatural\partightenfactor0

\f0\b \cf0 Loss: 71.94%\
Accuracy: 70.75%\
F1 score: 73.16%\
Precision: 64.33%\
Recall: 88.92%
\f1\b0 \
\
\
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardirnatural\partightenfactor0

\f0\b\fs24 \cf0 \ul \ulc0 NETWORK 3
\f1\b0\fs20 \ulnone \
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardirnatural\partightenfactor0
\cf0 _________________________________________________________________\
Layer (type)                 Output Shape              Param #   \
=================================================================\
lstm_1 (LSTM)                (None, 1, 300)            1081200   \
_________________________________________________________________\
lstm_2 (LSTM)                (None, 300)               721200    \
_________________________________________________________________\
dense_1 (Dense)              (None, 1)                 301       \
=================================================================\
Total params: 1,802,701\
Trainable params: 1,802,701\
Non-trainable params: 0\
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardirnatural\partightenfactor0
\cf0 Minibatch size: 40\
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardirnatural\partightenfactor0
\cf0 _________________________________________________________________\
None\
Train on 139618 samples, validate on 22258 samples\
Epoch 1/10\
 - 307s - loss: 0.4583 - acc: 0.7920 - f1_m: 0.8666 - precision_m: 0.7973 - recall_m: 0.9553 - val_loss: 0.6590 - val_acc: 0.6501 - val_f1_m: 0.7100 - val_precision_m: 0.5877 - val_recall_m: 0.9425\
Epoch 2/10\
 - 295s - loss: 0.4112 - acc: 0.8188 - f1_m: 0.8815 - precision_m: 0.8227 - recall_m: 0.9538 - val_loss: 0.6189 - val_acc: 0.6760 - val_f1_m: 0.7195 - val_precision_m: 0.6083 - val_recall_m: 0.9213\
Epoch 3/10\
 - 295s - loss: 0.3795 - acc: 0.8353 - f1_m: 0.8911 - precision_m: 0.8399 - recall_m: 0.9529 - val_loss: 0.6163 - val_acc: 0.6871 - val_f1_m: 0.7263 - val_precision_m: 0.6169 - val_recall_m: 0.9210\
Epoch 4/10\
 - 296s - loss: 0.3498 - acc: 0.8510 - f1_m: 0.9005 - precision_m: 0.8550 - recall_m: 0.9546 - val_loss: 0.5960 - val_acc: 0.7024 - val_f1_m: 0.7324 - val_precision_m: 0.6337 - val_recall_m: 0.9028\
Epoch 5/10\
 - 293s - loss: 0.3233 - acc: 0.8631 - f1_m: 0.9080 - precision_m: 0.8667 - recall_m: 0.9571 - val_loss: 0.6027 - val_acc: 0.6984 - val_f1_m: 0.7376 - val_precision_m: 0.6253 - val_recall_m: 0.9374\
Epoch 6/10\
 - 291s - loss: 0.2991 - acc: 0.8743 - f1_m: 0.9152 - precision_m: 0.8773 - recall_m: 0.9596 - val_loss: 0.6355 - val_acc: 0.7025 - val_f1_m: 0.7387 - val_precision_m: 0.6289 - val_recall_m: 0.9315\
Epoch 7/10\
 - 291s - loss: 0.2766 - acc: 0.8833 - f1_m: 0.9209 - precision_m: 0.8866 - recall_m: 0.9608 - val_loss: 0.6444 - val_acc: 0.7137 - val_f1_m: 0.7404 - val_precision_m: 0.6464 - val_recall_m: 0.9013\
Epoch 8/10\
 - 290s - loss: 0.2570 - acc: 0.8921 - f1_m: 0.9264 - precision_m: 0.8950 - recall_m: 0.9629 - val_loss: 0.6502 - val_acc: 0.7186 - val_f1_m: 0.7403 - val_precision_m: 0.6524 - val_recall_m: 0.8885\
Epoch 9/10\
 - 312s - loss: 0.2386 - acc: 0.9002 - f1_m: 0.9317 - precision_m: 0.9030 - recall_m: 0.9649 - val_loss: 0.7537 - val_acc: 0.7093 - val_f1_m: 0.7410 - val_precision_m: 0.6373 - val_recall_m: 0.9211\
Epoch 10/10\
 - 363s - loss: 0.2215 - acc: 0.9069 - f1_m: 0.9362 - precision_m: 0.9106 - recall_m: 0.9655 - val_loss: 0.7234 - val_acc: 0.7183 - val_f1_m: 0.7399 - val_precision_m: 0.6531 - val_recall_m: 0.8872\
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardirnatural\partightenfactor0

\f0\b \cf0 Loss: 72.34%\
Accuracy: 71.83%\
F1 score: 73.80%\
Precision: 65.33%\
Recall: 88.64%
\f1\b0 \
\
\
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardirnatural\partightenfactor0

\f0\b\fs24 \cf0 \ul \ulc0 NETWORK 4
\f1\b0\fs20 \ulnone \
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardirnatural\partightenfactor0
\cf0 _________________________________________________________________\
Layer (type)                 Output Shape              Param #   \
=================================================================\
lstm_1 (LSTM)                (None, 300)               1081200   \
_________________________________________________________________\
dense_1 (Dense)              (None, 1)                 301       \
=================================================================\
Total params: 1,081,501\
Trainable params: 1,081,501\
Non-trainable params: 0\
Minibatch size: 40\
_________________________________________________________________\
None\
Train on 139618 samples, validate on 22258 samples\
Epoch 1/10\
 - 180s - loss: 0.4718 - acc: 0.7874 - f1_m: 0.8627 - precision_m: 0.7989 - recall_m: 0.9438 - val_loss: 0.6367 - val_acc: 0.6552 - val_f1_m: 0.7061 - val_precision_m: 0.5934 - val_recall_m: 0.9148\
Epoch 2/10\
 - 171s - loss: 0.4348 - acc: 0.8069 - f1_m: 0.8739 - precision_m: 0.8149 - recall_m: 0.9468 - val_loss: 0.6365 - val_acc: 0.6595 - val_f1_m: 0.7130 - val_precision_m: 0.5951 - val_recall_m: 0.9327\
Epoch 3/10\
 - 197s - loss: 0.4101 - acc: 0.8216 - f1_m: 0.8826 - precision_m: 0.8287 - recall_m: 0.9483 - val_loss: 0.6380 - val_acc: 0.6635 - val_f1_m: 0.7172 - val_precision_m: 0.5965 - val_recall_m: 0.9417\
Epoch 4/10\
 - 184s - loss: 0.3886 - acc: 0.8335 - f1_m: 0.8896 - precision_m: 0.8393 - recall_m: 0.9503 - val_loss: 0.6388 - val_acc: 0.6691 - val_f1_m: 0.7204 - val_precision_m: 0.6004 - val_recall_m: 0.9427\
Epoch 5/10\
 - 170s - loss: 0.3673 - acc: 0.8445 - f1_m: 0.8964 - precision_m: 0.8497 - recall_m: 0.9522 - val_loss: 0.6301 - val_acc: 0.6881 - val_f1_m: 0.7296 - val_precision_m: 0.6164 - val_recall_m: 0.9325\
Epoch 6/10\
 - 170s - loss: 0.3488 - acc: 0.8534 - f1_m: 0.9019 - precision_m: 0.8583 - recall_m: 0.9538 - val_loss: 0.5945 - val_acc: 0.7055 - val_f1_m: 0.7346 - val_precision_m: 0.6351 - val_recall_m: 0.9052\
Epoch 7/10\
 - 170s - loss: 0.3310 - acc: 0.8618 - f1_m: 0.9071 - precision_m: 0.8667 - recall_m: 0.9548 - val_loss: 0.5848 - val_acc: 0.7132 - val_f1_m: 0.7336 - val_precision_m: 0.6494 - val_recall_m: 0.8752\
Epoch 8/10\
 - 169s - loss: 0.3143 - acc: 0.8702 - f1_m: 0.9123 - precision_m: 0.8747 - recall_m: 0.9564 - val_loss: 0.6457 - val_acc: 0.6985 - val_f1_m: 0.7348 - val_precision_m: 0.6257 - val_recall_m: 0.9265\
Epoch 9/10\
 - 170s - loss: 0.2996 - acc: 0.8763 - f1_m: 0.9164 - precision_m: 0.8810 - recall_m: 0.9578 - val_loss: 0.6358 - val_acc: 0.7096 - val_f1_m: 0.7371 - val_precision_m: 0.6410 - val_recall_m: 0.9027\
Epoch 10/10\
 - 169s - loss: 0.2854 - acc: 0.8825 - f1_m: 0.9202 - precision_m: 0.8878 - recall_m: 0.9580 - val_loss: 0.6387 - val_acc: 0.7125 - val_f1_m: 0.7369 - val_precision_m: 0.6468 - val_recall_m: 0.8913\
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardirnatural\partightenfactor0

\f0\b \cf0 Loss: 63.87%\
Accuracy: 71.25%\
F1 score: 73.67%\
Precision: 64.94%\
Recall: 89.19%
\f1\b0 \
\
\
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardirnatural\partightenfactor0

\f0\b\fs24 \cf0 \ul \ulc0 NETWORK 5
\f1\b0\fs20 \ulnone \
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardirnatural\partightenfactor0
\cf0 _________________________________________________________________\
Layer (type)                 Output Shape              Param #   \
=================================================================\
lstm_1 (LSTM)                (None, 300)               1081200   \
_________________________________________________________________\
dense_1 (Dense)              (None, 1)                 301       \
=================================================================\
Total params: 1,081,501\
Trainable params: 1,081,501\
Non-trainable params: 0\
Minibatch size: 1000\
_________________________________________________________________\
None\
Train on 139618 samples, validate on 22258 samples\
Epoch 1/10\
 - 21s - loss: 0.5664 - acc: 0.7215 - f1_m: 0.8325 - precision_m: 0.7270 - recall_m: 0.9874 - val_loss: 0.6907 - val_acc: 0.5809 - val_f1_m: 0.6870 - val_precision_m: 0.5423 - val_recall_m: 0.9392\
Epoch 2/10\
 - 17s - loss: 0.4778 - acc: 0.7832 - f1_m: 0.8620 - precision_m: 0.7945 - recall_m: 0.9427 - val_loss: 0.6537 - val_acc: 0.6501 - val_f1_m: 0.7141 - val_precision_m: 0.5960 - val_recall_m: 0.8924\
Epoch 3/10\
 - 17s - loss: 0.4599 - acc: 0.7957 - f1_m: 0.8682 - precision_m: 0.8090 - recall_m: 0.9371 - val_loss: 0.6802 - val_acc: 0.6455 - val_f1_m: 0.7182 - val_precision_m: 0.5888 - val_recall_m: 0.9222\
Epoch 4/10\
 - 17s - loss: 0.4543 - acc: 0.7993 - f1_m: 0.8703 - precision_m: 0.8121 - recall_m: 0.9379 - val_loss: 0.6776 - val_acc: 0.6460 - val_f1_m: 0.7188 - val_precision_m: 0.5889 - val_recall_m: 0.9238\
Epoch 5/10\
 - 17s - loss: 0.4500 - acc: 0.8018 - f1_m: 0.8719 - precision_m: 0.8138 - recall_m: 0.9393 - val_loss: 0.6518 - val_acc: 0.6572 - val_f1_m: 0.7210 - val_precision_m: 0.6001 - val_recall_m: 0.9049\
Epoch 6/10\
 - 19s - loss: 0.4453 - acc: 0.8042 - f1_m: 0.8735 - precision_m: 0.8151 - recall_m: 0.9411 - val_loss: 0.6478 - val_acc: 0.6591 - val_f1_m: 0.7214 - val_precision_m: 0.6020 - val_recall_m: 0.9013\
Epoch 7/10\
 - 18s - loss: 0.4413 - acc: 0.8058 - f1_m: 0.8744 - precision_m: 0.8162 - recall_m: 0.9419 - val_loss: 0.6566 - val_acc: 0.6555 - val_f1_m: 0.7232 - val_precision_m: 0.5968 - val_recall_m: 0.9190\
Epoch 8/10\
 - 18s - loss: 0.4369 - acc: 0.8082 - f1_m: 0.8759 - precision_m: 0.8180 - recall_m: 0.9430 - val_loss: 0.6530 - val_acc: 0.6567 - val_f1_m: 0.7242 - val_precision_m: 0.5976 - val_recall_m: 0.9208\
Epoch 9/10\
 - 18s - loss: 0.4321 - acc: 0.8102 - f1_m: 0.8771 - precision_m: 0.8196 - recall_m: 0.9436 - val_loss: 0.6465 - val_acc: 0.6597 - val_f1_m: 0.7260 - val_precision_m: 0.5998 - val_recall_m: 0.9210\
Epoch 10/10\
 - 18s - loss: 0.4278 - acc: 0.8124 - f1_m: 0.8785 - precision_m: 0.8213 - recall_m: 0.9449 - val_loss: 0.6374 - val_acc: 0.6651 - val_f1_m: 0.7282 - val_precision_m: 0.6050 - val_recall_m: 0.9164\
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardirnatural\partightenfactor0

\f0\b \cf0 Loss: 63.74%\
Accuracy: 66.51%\
F1 score: 71.11%\
Precision: 60.16%\
Recall: 91.50%\
\
\
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardirnatural\partightenfactor0

\fs24 \cf0 \ul \ulc0 NETWORK 6
\fs20 \ulnone \
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardirnatural\partightenfactor0

\f1\b0 \cf0 _________________________________________________________________\
Layer (type)                 Output Shape              Param #   \
=================================================================\
lstm_1 (LSTM)                (None, 1, 600)            2882400   \
_________________________________________________________________\
lstm_2 (LSTM)                (None, 600)               2882400   \
_________________________________________________________________\
dense_1 (Dense)              (None, 1)                 601       \
=================================================================\
Total params: 5,765,401\
Trainable params: 5,765,401\
Non-trainable params: 0\
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardirnatural\partightenfactor0
\cf0 Minibatch size: 40\
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardirnatural\partightenfactor0
\cf0 _________________________________________________________________\
None\
Train on 139618 samples, validate on 22258 samples\
Epoch 1/10\
 - 1011s - loss: 0.4559 - acc: 0.7932 - f1_m: 0.8676 - precision_m: 0.7957 - recall_m: 0.9594 - val_loss: 0.6321 - val_acc: 0.6510 - val_f1_m: 0.7072 - val_precision_m: 0.5905 - val_recall_m: 0.9274\
Epoch 2/10\
 - 991s - loss: 0.4060 - acc: 0.8208 - f1_m: 0.8823 - precision_m: 0.8260 - recall_m: 0.9513 - val_loss: 0.6380 - val_acc: 0.6608 - val_f1_m: 0.7161 - val_precision_m: 0.5939 - val_recall_m: 0.9456\
Epoch 3/10\
 - 1007s - loss: 0.3719 - acc: 0.8387 - f1_m: 0.8929 - precision_m: 0.8433 - recall_m: 0.9527 - val_loss: 0.6257 - val_acc: 0.6830 - val_f1_m: 0.7290 - val_precision_m: 0.6114 - val_recall_m: 0.9429\
Epoch 4/10\
 - 1016s - loss: 0.3401 - acc: 0.8553 - f1_m: 0.9032 - precision_m: 0.8583 - recall_m: 0.9566 - val_loss: 0.6024 - val_acc: 0.7001 - val_f1_m: 0.7337 - val_precision_m: 0.6297 - val_recall_m: 0.9160\
Epoch 5/10\
 - 979s - loss: 0.3122 - acc: 0.8689 - f1_m: 0.9118 - precision_m: 0.8712 - recall_m: 0.9598 - val_loss: 0.6435 - val_acc: 0.6985 - val_f1_m: 0.7340 - val_precision_m: 0.6272 - val_recall_m: 0.9226\
Epoch 6/10\
 - 931s - loss: 0.2870 - acc: 0.8794 - f1_m: 0.9186 - precision_m: 0.8814 - recall_m: 0.9618 - val_loss: 0.6298 - val_acc: 0.7098 - val_f1_m: 0.7359 - val_precision_m: 0.6439 - val_recall_m: 0.8957\
Epoch 7/10\
 - 1071s - loss: 0.2654 - acc: 0.8884 - f1_m: 0.9243 - precision_m: 0.8900 - recall_m: 0.9640 - val_loss: 0.6114 - val_acc: 0.7178 - val_f1_m: 0.7364 - val_precision_m: 0.6557 - val_recall_m: 0.8744\
Epoch 8/10\
 - 1069s - loss: 0.2445 - acc: 0.8968 - f1_m: 0.9296 - precision_m: 0.8991 - recall_m: 0.9646 - val_loss: 0.6610 - val_acc: 0.7058 - val_f1_m: 0.7376 - val_precision_m: 0.6359 - val_recall_m: 0.9145\
Epoch 9/10\
 - 1040s - loss: 0.2257 - acc: 0.9052 - f1_m: 0.9351 - precision_m: 0.9075 - recall_m: 0.9667 - val_loss: 0.7523 - val_acc: 0.7128 - val_f1_m: 0.7378 - val_precision_m: 0.6459 - val_recall_m: 0.8956\
Epoch 10/10\
 - 999s - loss: 0.2085 - acc: 0.9126 - f1_m: 0.9399 - precision_m: 0.9149 - recall_m: 0.9685 - val_loss: 0.7565 - val_acc: 0.7175 - val_f1_m: 0.7388 - val_precision_m: 0.6526 - val_recall_m: 0.8861
\f0\b \
Loss: 75.65%\
Accuracy: 71.75%\
F1 score: 73.79%\
Precision: 65.45%\
Recall: 88.54%
\f1\b0 \
\
\
}